<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>【论文阅读笔记】面向医学文本的实体关系抽取研究综述 | 东北石油大学智能技术与自然语言处理实验室</title><meta name="description" content="【论文阅读笔记】面向医学文本的实体关系抽取研究综述"><meta name="keywords" content="NLP,深度学习,论文,信息抽取"><meta name="author" content="东北石油大学智能技术与自然语言处理实验室"><meta name="copyright" content="东北石油大学智能技术与自然语言处理实验室"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/ava.jpg"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="【论文阅读笔记】面向医学文本的实体关系抽取研究综述"><meta name="twitter:description" content="【论文阅读笔记】面向医学文本的实体关系抽取研究综述"><meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200913100939442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center"><meta property="og:type" content="article"><meta property="og:title" content="【论文阅读笔记】面向医学文本的实体关系抽取研究综述"><meta property="og:url" content="https://nlplab406.github.io/2020/09/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91%E9%9D%A2%E5%90%91%E5%8C%BB%E5%AD%A6%E6%96%87%E6%9C%AC%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0/"><meta property="og:site_name" content="东北石油大学智能技术与自然语言处理实验室"><meta property="og:description" content="【论文阅读笔记】面向医学文本的实体关系抽取研究综述"><meta property="og:image" content="https://img-blog.csdnimg.cn/20200913100939442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://nlplab406.github.io/2020/09/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91%E9%9D%A2%E5%90%91%E5%8C%BB%E5%AD%A6%E6%96%87%E6%9C%AC%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0/"><link rel="next" title="git pycharm 你会遇到的坑 我帮你填" href="https://nlplab406.github.io/2020/08/24/git%20pycharm%20%E4%BD%A0%E4%BC%9A%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%20%E6%88%91%E5%B8%AE%E4%BD%A0%E5%A1%AB/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: true,
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">东北石油大学智能技术与自然语言处理实验室</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/ava.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">31</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">32</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">31</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#写在前面"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">写在前面</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#深度学习方法"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">深度学习方法</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#监督学习"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">监督学习</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#基于简单的CNN模型"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">基于简单的CNN模型</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#基于CNN模型的改进"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">基于CNN模型的改进</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#基于RNN模型"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">基于RNN模型</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#基于注意力机制的模型"><span class="toc_mobile_items-number">2.4.</span> <span class="toc_mobile_items-text">基于注意力机制的模型</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#远程监督的多实例学习"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">远程监督的多实例学习</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#分段卷积神经网络模型及改进"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">分段卷积神经网络模型及改进</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#多实例、多标签CNNs模型"><span class="toc_mobile_items-number">3.2.</span> <span class="toc_mobile_items-text">多实例、多标签CNNs模型</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#深层记忆网络模型"><span class="toc_mobile_items-number">3.3.</span> <span class="toc_mobile_items-text">深层记忆网络模型</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#引入外部知识模型"><span class="toc_mobile_items-number">3.4.</span> <span class="toc_mobile_items-text">引入外部知识模型</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#实体关系联合抽取"><span class="toc_mobile_items-number">3.5.</span> <span class="toc_mobile_items-text">实体关系联合抽取</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#未来研究方向"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">未来研究方向</span></a></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#写在前面"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#深度学习方法"><span class="toc-number">1.1.</span> <span class="toc-text">深度学习方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#监督学习"><span class="toc-number">2.</span> <span class="toc-text">监督学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#基于简单的CNN模型"><span class="toc-number">2.1.</span> <span class="toc-text">基于简单的CNN模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基于CNN模型的改进"><span class="toc-number">2.2.</span> <span class="toc-text">基于CNN模型的改进</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基于RNN模型"><span class="toc-number">2.3.</span> <span class="toc-text">基于RNN模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基于注意力机制的模型"><span class="toc-number">2.4.</span> <span class="toc-text">基于注意力机制的模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#远程监督的多实例学习"><span class="toc-number">3.</span> <span class="toc-text">远程监督的多实例学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#分段卷积神经网络模型及改进"><span class="toc-number">3.1.</span> <span class="toc-text">分段卷积神经网络模型及改进</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多实例、多标签CNNs模型"><span class="toc-number">3.2.</span> <span class="toc-text">多实例、多标签CNNs模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#深层记忆网络模型"><span class="toc-number">3.3.</span> <span class="toc-text">深层记忆网络模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#引入外部知识模型"><span class="toc-number">3.4.</span> <span class="toc-text">引入外部知识模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实体关系联合抽取"><span class="toc-number">3.5.</span> <span class="toc-text">实体关系联合抽取</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#未来研究方向"><span class="toc-number">4.</span> <span class="toc-text">未来研究方向</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://img-blog.csdnimg.cn/20200913100939442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center)"><div id="post-info"><div id="post-title"><div class="posttitle">【论文阅读笔记】面向医学文本的实体关系抽取研究综述</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-09-13<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-09-13</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%88%98%E5%A6%82%E6%84%8F/">刘如意</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%88%98%E5%A6%82%E6%84%8F/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/">信息抽取</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">4.1k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 12 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><p><a href="https://img-blog.csdnimg.cn/20200913100939442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200913100939442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" class="lazyload"></a></p>
<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>&emsp;&emsp;这篇文章从<strong>实体关系抽取</strong>的相关概念引人，描述了深度学习方法在医学领域实体关系抽取的发展历程，也从构建数据集的方面对监督学习和远程监督多实例学习模型进行阐述，并展望了医学文本实体关系抽取的未来研究方向。这里主要讲一下实体关系抽取模型的发展，前面的关于一些实体关系抽取的相关概念，命名实体识别、实体关系抽取、监督学习等概念的介绍就不赘述了。</p>
<h2 id="深度学习方法"><a href="#深度学习方法" class="headerlink" title="深度学习方法"></a>深度学习方法</h2><p>&emsp;&emsp;深度学习方法的<font color="#dddd00">优势</font>在于无须领域专家指定复杂的抽取特征，神经网络模型自身就可以学习到句子中隐藏的语义信息。下图为深度学习的实体关系抽取框架，从输入数据到评价指标都有不同的方法来实现。</p>
<p><a href="https://img-blog.csdnimg.cn/20200913103811634.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200913103811634.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" class="lazyload"></a></p>
<h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><p>&emsp;&emsp;早期利用深度学习技术进行关系抽取是在人工标注语料库的监督训练模式下进行的。基于有监督的实体关系抽取框架的演化过程如下图。通过将问题建模为多酚类问题，模型会尝试为句子中每一个实体对预测相应的关系类型。</p>
<p><a href="https://img-blog.csdnimg.cn/20200913104251239.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" target="_blank" rel="noopener" data-fancybox="group" data-caption="从传统的基于规则特征核函数等方法存在的一定的缺点到监督学习逐步在克服以前的缺点得到模型的改善" class="fancybox"><img alt="从传统的基于规则特征核函数等方法存在的一定的缺点到监督学习逐步在克服以前的缺点得到模型的改善" title="从传统的基于规则特征核函数等方法存在的一定的缺点到监督学习逐步在克服以前的缺点得到模型的改善" data-src="https://img-blog.csdnimg.cn/20200913104251239.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" class="lazyload"></a></p>
<h2 id="基于简单的CNN模型"><a href="#基于简单的CNN模型" class="headerlink" title="基于简单的CNN模型"></a>基于简单的CNN模型</h2><p>&emsp;&emsp;<font color="#dddd00">Liu</font>等用CNN网络取代手工构建文本特征，从而实现自动提取特征，并构造了一个从端到端的网络，用词向量和词法特征对输入的句子进行编码，经过卷积层、全连接层、SoftMax层给出最终所有类别的概率分布。这个模型使用同义词向量代替预训练词向量。后面==Zeng==等在之前的基础上模型选用了预训练词向量，其提出使用的位置嵌入向量成为了深度学习关系抽取模型的标准。<strong>在生物医学领域</strong><font color="#dddd00">Sahu</font>首次提出将CNN用于提取临床文本中医学实体之间的关系，除了词向量和位置向量，模型的输入还增加了磁性特征、词干特征、实体类型来丰富句子的表示形式并且在i2b2/VA临床关系抽取数据集上取得比以往最优的效果。</p>
<h2 id="基于CNN模型的改进"><a href="#基于CNN模型的改进" class="headerlink" title="基于CNN模型的改进"></a>基于CNN模型的改进</h2><p>&emsp;&emsp;<font color="#dddd00">Nguyen</font>等在关系抽取的监督学习研究领域提出了拥有多尺寸窗口内核的<strong>MW-CNN</strong>模型。这个模型就是完全摆脱了利用外部词汇特征类丰富数据句子的表示形式，而是让CNN自己学习需要的特征。输入层由词向量和位置向量组成，上层为卷积层和最大池化层，利用了不同的窗口大小的卷积核来捕获更广泛的n-gram信息。实验表明使用2、3、4、5窗口长度的内核可以提供最佳的性能。</p>
<h2 id="基于RNN模型"><a href="#基于RNN模型" class="headerlink" title="基于RNN模型"></a>基于RNN模型</h2><p>&emsp;&emsp;由于CNN存在一定的缺点就是无法学习到时序特征，特别是实体对之间长距离依赖关系。所以<font color="#dddd00">Zhang</font>等尝试基于RNN建模长距离关系抽取模式达到比较好的效果。这样的循环模型不仅在<em>SemEval-2010task8</em>数据集上表现良好，还在<em>KBT37</em>数据集上获得更明显的提升效果。所以实验验证了RNN的记忆优势适合对长文本进行建模。==Zhou==等提出集成基于特征的模型、基于核函数模型和神经网络模型的抽取框架，用于化学致病关系抽取任务，基于特征的模型获取表层词汇特征、基于核函数的模型捕捉结构化句法特征以及神经网络模型利用语义表示信息。<strong>生物医学领域</strong><font color="#dddd00">Chikka</font>等提出的双向长短时记忆网络(Bi-LSTM)和基于规则的方法解决<em>i2b2-2010</em>数据集中抽取疾病和治疗药物关系子任务。这个模型将单次级别特征(字向量、词向量、词性和位置特征)拼接后输入Bi-LSTM，之后将Bi-LSTM输出结果与句子级别特征拼接后输入至线性层判断关系类型。</p>
<h2 id="基于注意力机制的模型"><a href="#基于注意力机制的模型" class="headerlink" title="基于注意力机制的模型"></a>基于注意力机制的模型</h2><p>&emsp;&emsp;深度学习方法的使用为减少手工制定特征提供可能,但是模型不可避免地会使用一些词汇资源( 如WordNet)和NLP系统(如依赖解析器和命名实体识别) 来获取高维特征。 另外,重要信息可能出现在句中的任何位置。 因此<font color="#dddd00">Zhou</font> 等 提出基于神经注意力机制的 Bi-LSTM 框架,在不使用额外知识和自然语言处理系统的情况下,自动聚焦于对分类有决定性影响的词,捕捉句子中最重要的语义信息,该模型与基于排序的CR-CNN 模型效果一致。目前基于注意力机制的双向LSTM模型已经成为自然语言处理任务的标配,在关系分类任务上也取得了不错的效果,数据集中同种关系可以用多种不同的形式进行表述。<font color="#dddd00">Wang</font>等提出基于两层注意力机制(实体级注意力机制和关系级池化注意力机制)的卷积神经网络框架,用于学习不同结构的句子中与目标分类最相关的元素。实体级注意力(第一层注意力)机制用于输入层,通过计算句中单词与目标实体的余弦相似度,突出句中与目标实体相关的部分;关系级池化注意力(第二层注意力)机制用于卷积后池化阶段,确定与目标关系相关的部分。该模型在SemEval-2010 task 8数据集上的F1值达到 88. 0%,优于依赖丰富先验知识的方法。</p>
<h1 id="远程监督的多实例学习"><a href="#远程监督的多实例学习" class="headerlink" title="远程监督的多实例学习"></a>远程监督的多实例学习</h1><p>&emsp;&emsp;<font color="#dddd00">Riedel</font>等为解决远程监督的局限性,放宽远程监督假设的限制,建模假设“ 如果实体对存在某种关系,那么包中至少有一个句子反映该关系” ,将任务建模为<strong>多实例学习</strong>问题。基于远程监督的实体关系抽取框架的演化过程如图所示。这样就可以利用远程监督创建大规模的训练数据，同时对标签中的噪声具有更好的鲁棒性。多实例学习是有监督学习的一种形式，将一组句子规定为一个包,通过对一个包进行标注,而不再需要标注每一个句子实例。在关系抽取中,每个实体对定义为一个包,包中包含着存在该实体对的所有句子。</p>
<p><a href="https://img-blog.csdnimg.cn/20200913150602594.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200913150602594.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" class="lazyload"></a></p>
<h2 id="分段卷积神经网络模型及改进"><a href="#分段卷积神经网络模型及改进" class="headerlink" title="分段卷积神经网络模型及改进"></a>分段卷积神经网络模型及改进</h2><p>&emsp;&emsp;<font color="#dddd00">Zeng</font>等提出了<strong>分段卷积神经网络</strong>(<font color="#dddd00">PCNNs</font>)，使用多实例学习的模式，借助神经网络模型建立一个远程监督数据的关系抽取器，其重要贡献是提出了跨越整个句子的分段最大池化，这样的最大池化层虽然大大减小了隐藏层的大小，但是不足以捕获句子中实体之间的结构。因此,可以通过对句子的不同段池化而不是整个句子的最大池化来加以避免。 每个句子可以很自然地根据两个实体分为三部分,通过在每个段内执行分段最大池化以获得更丰富的表示,同时仍然保留与输入句子长度无关的向量。由于该方法假设“包中至少有一条语句表达实体对之间的关系” ,因此在训练和测试阶段仅使用最大概率的语句,这意味着模型忽略包中由其他句子提供的大量有用数据信息。即使包中并非所有句子都表达实体对之间的正确关系,但仅使用单个句子是异常严格的约束。借助多实例学习的<font color="#dddd00">PCNNs</font>模型表现出优于传统非深度学习模型的性能,针对多实例问题,对单个包中所有的实例使用注意力机制。当使用包中所有实例的加权注意力机制表示损失时,模型能够从噪声中识别重要句子,并且利用包中的所有信息来进行关系类别预测。可以观察到,“只有一句最有可能的句子” 的模型是句子级注意力机制的一个特例,即最有可能的句子的权重为1,而其他句子的权重都为0。结果表明,使用<em>句子级注意力机制</em>模型可以显著提高CNN和PCNN模型的准确率与召回率。由于模型学习到散落在多实例中的信息,因此能够以较高的置信度预测正确的关系类型。</p>
<h2 id="多实例、多标签CNNs模型"><a href="#多实例、多标签CNNs模型" class="headerlink" title="多实例、多标签CNNs模型"></a>多实例、多标签CNNs模型</h2><p>&emsp;&emsp;<font color="#dddd00">Jiang</font>等提出了多实例、多标签的<font color="#dddd00">CNNs</font>(multi-instance multi-label CNNs,MIMLCNNs)模型,使用跨文档的最大池化层解决信息损失问题。类似于前文所述的注意力机制,首先对包i中的每个句子dji 确定一个向量表示rji, 然后采用句子向量维数的最大值来确定包i的最终向量表示。这使得最终特征向量的每个特征都来自于最相关的文档,而不是整个特征向量来自于包中最相关的一个文档。 同时,也解决了关系抽取的多标签问题。 到目前为止,已有模型对一个实体对仅预测单个关系类型,但是相同的实体对可能从不同文档抽取多种关系(称为重叠关系) 。例如〈麻疹,传播途径,咳嗽〉和〈 麻疹,临床表现,咳嗽〉,对于相同的实体对〈麻疹,咳嗽〉来说都是有效的关系。于是在最终的分类层将<strong>SoftMax</strong>改为<strong>Sigmoid</strong>,这意味着网络独立地预测每个关系类别的概率,而不是预测所有关系上的概率分布。由于MIMLCNNs模型能利用包中多个文档的信息,因此能够像句子级注意力机制一样提升PCNN和CNN模型的性能。</p>
<h2 id="深层记忆网络模型"><a href="#深层记忆网络模型" class="headerlink" title="深层记忆网络模型"></a>深层记忆网络模型</h2><p>&emsp;&emsp;<font color="#dddd00">Feng</font>等提出,不同的单词在不同关系类型下以及对不同的实体对重要程度不同,这一点类似于监督学习中的多层注意力机制。同时,关系类型之间并不是独立的,会有<strong>重叠依赖现象</strong>,即所提出的多标签,本质上是因为标签之间有相互依赖关系,如果〈 A, capital, B〉成立,〈 A, contains, B〉也会成立。对于第一个问题,借鉴多层注意力的输入层注意力机制的思路,即根据单词与实体对的相似度来分配权重,但是这里不使用传统的注意力,而是基于记忆网络的思想。对于第二个问题,使用多层关系的注意力机制来引入关系类型之间相关度。利用单词级别的思路计算单词与目标实体的相关性,并且利用多层来挖掘更深层次的关系。关系级的动机则是考虑到数据中的关系依赖性,使用注意力来考虑关系之间的相关性。</p>
<h2 id="引入外部知识模型"><a href="#引入外部知识模型" class="headerlink" title="引入外部知识模型"></a>引入外部知识模型</h2><p>&emsp;&emsp;<font color="#dddd00">Ji</font>等引入额外的知识图谱信息,即实体描述信息。例如,<em>NYT</em>数据集是通过与 Freebase 做实体链接等来链接句子中的实体,而其实每个实体在 Freebase 都有一段文字描述。该研究认为现有工作集中在NYT和Freebase数据本身上,忽略了数据集背后的知识图谱信息,因此引入实体描述信息加强对实体嵌入的学习。此外,在处理多实例学习方面,同样使用了句子级注意力机制。 模型分为<strong>输入模块、注意力模块和实体描述模块</strong>三部分,其中输入模块中每个句子的词由词向量与位置向量连接表示,接着是卷积层与分段最大池化层,最终得到每个句子的向量。 模型上层则是用来解决多实例学习的注意力模块,计算包内每个实例与关系类型的相关性确定权重。 该研究的贡献主要在于从知识图谱中引入额外的实体描述信息,加强嵌入向量的学习。不过两部分的融合在本质上相当于在原有基础上加一个范式约束而已,或者说一个先验的惩罚项。</p>
<h2 id="实体关系联合抽取"><a href="#实体关系联合抽取" class="headerlink" title="实体关系联合抽取"></a>实体关系联合抽取</h2><p>&emsp;&emsp;大多数联合抽取的神经模型采用<strong>参数共享</strong>的方式来实现联合抽取。为获取关系三元组,模型需要将检测到的实体对输入到关系分类器,以识别实体之间的关系。单独解码设计导致实体识别与关系抽取的训练目标分离,使得实体识别任务和关系预测任务之间的联系被切断。<font color="#dddd00">Zheng</font> 等通过引入一种全新的统一标注方案来实现联合编码,将三元组关系抽取任务转化为不需要NER或RC的端到端序列标注问题。由于实体和关系的信息被集成到统一的标注方案中,因此模型可以将关系三元组作为一个整体来学习。然而,句子中可能会包含多个三元组,且存在前文所描述的三元组实体重叠现象。<font color="#dddd00">Zeng</font>等提出一种具有拷贝机制的序列到序列模型;<font color="#dddd00">Fu</font>等提出基于图卷积网络( graph convolutional network,GCN) 的方法;Wei等使用预训练模型 BERT 进行编码,并设计一种分层二进制标注策略,将实体对的语义关系视为主体到客体的映射函数。</p>
<h1 id="未来研究方向"><a href="#未来研究方向" class="headerlink" title="未来研究方向"></a>未来研究方向</h1><p>&emsp;&emsp;根据所采用数据集的构建方式,前文分别回顾了监督学习和远程监督的多实例学习模型。下表记录了监督学习模型在BioCreative V数据集CID任务上的结果,以及远程监督的多实例学习模型在 NYT 数据集和WebNLG数据集上的结果。从表可以看出,监督学习模型和远程监督的多实例学习模型在数据集上的性能在持续提升。深度学习模型所使用的数据集中,预先定义的关系类别分布均匀且提供丰富的训练样例,单个样例表述相对简短、关系密度低,需要抽取三元组重叠现象并不严重。</p>
<p><a href="https://img-blog.csdnimg.cn/20200913153408657.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200913153408657.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70#pic_center" class="lazyload"></a></p>
<p>&emsp;&emsp;为准确高效地扩展知识图谱,从海量非结构化医学文本中自动获取新的世界知识已成为必由之路。以实体关系抽取为代表的知识获取技术已经取得一些成果,特别是近年来深度学习模型极大推动了关系抽取研究的发展。本文依据数据集的构建方式,详细阐述了监督学习和远程监督的多实例学习,对相关模型的优点和不足进行分析,并探讨了面向医学文本的实体关系抽取任务所面临的多种挑战和未来发展方向。</p>
<p>原文链接：<a href="https://blog.csdn.net/weixin_45684408/article/details/108555124" target="_blank" rel="noopener">面向医学文本的实体关系抽取研究综述</a></p>
</div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NLP/">NLP    </a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习    </a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文    </a><a class="post-meta__tags" href="/tags/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/">信息抽取    </a></div><div class="post_share"></div></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2020/08/24/git%20pycharm%20%E4%BD%A0%E4%BC%9A%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%20%E6%88%91%E5%B8%AE%E4%BD%A0%E5%A1%AB/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.9/img/闫凯峰/8.24/图片 1.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>git pycharm 你会遇到的坑 我帮你填</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/10/【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training/" title="【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/2020071920490854.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-10</div><div class="relatedPosts_title">【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/01/【论文阅读笔记PCNN】Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks/" title="【论文阅读笔记PCNN】Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200801134611553.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-01</div><div class="relatedPosts_title">【论文阅读笔记PCNN】Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/24/git pycharm 你会遇到的坑 我帮你填/" title="git pycharm 你会遇到的坑 我帮你填"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.9/img/闫凯峰/8.24/图片 1.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-24</div><div class="relatedPosts_title">git pycharm 你会遇到的坑 我帮你填</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/分类任务评价指标/" title="分类任务评价指标"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/zhengguanyu/PhotoRepos@v1.1/img/封面.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">分类任务评价指标</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/24/置信学习清洗脏数据/" title="置信学习清洗脏数据"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.10/img/闫凯峰/8.25/3连.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-24</div><div class="relatedPosts_title">置信学习清洗脏数据</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/04/论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》/" title="论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200803210957976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-04</div><div class="relatedPosts_title">论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By 东北石油大学智能技术与自然语言处理实验室</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">欢迎来到我们团队的博客！</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>