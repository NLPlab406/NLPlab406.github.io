<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training | 东北石油大学智能技术与自然语言处理实验室</title><meta name="description" content="【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training"><meta name="keywords" content="NLP,深度学习,论文,信息抽取"><meta name="author" content="东北石油大学智能技术与自然语言处理实验室"><meta name="copyright" content="东北石油大学智能技术与自然语言处理实验室"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/ava.jpg"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training"><meta name="twitter:description" content="【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training"><meta name="twitter:image" content="https://img-blog.csdnimg.cn/2020071920490854.png"><meta property="og:type" content="article"><meta property="og:title" content="【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training"><meta property="og:url" content="https://nlplab406.github.io/2020/08/10/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Span-based%20Joint%20Entity%20and%20Relation%20Extraction%20with%20Transformer%20Pre-training/"><meta property="og:site_name" content="东北石油大学智能技术与自然语言处理实验室"><meta property="og:description" content="【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training"><meta property="og:image" content="https://img-blog.csdnimg.cn/2020071920490854.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://nlplab406.github.io/2020/08/10/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Span-based%20Joint%20Entity%20and%20Relation%20Extraction%20with%20Transformer%20Pre-training/"><link rel="prev" title="知识图谱总体构建思路（非结构化文本数据）" href="https://nlplab406.github.io/2020/08/10/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%80%BB%E4%BD%93%E6%9E%84%E5%BB%BA%E6%80%9D%E8%B7%AF%EF%BC%88%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%EF%BC%89/"><link rel="next" title="知识图谱(一)：概述" href="https://nlplab406.github.io/2020/08/09/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1(%E4%B8%80)%EF%BC%9A%E6%A6%82%E8%BF%B0/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: true,
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">东北石油大学智能技术与自然语言处理实验室</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/ava.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">21</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">23</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">30</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#摘要"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">摘要</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#介绍"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">介绍</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#相关工作"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">相关工作</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Joint-Entity-and-Relation-Extraction"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">Joint Entity and Relation Extraction</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Span-based-Approaches"><span class="toc_mobile_items-number">3.2.</span> <span class="toc_mobile_items-text">Span-based Approaches</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#模型架构"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">模型架构</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Span-Classification"><span class="toc_mobile_items-number">4.1.</span> <span class="toc_mobile_items-text">Span Classification</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Span-Filtering"><span class="toc_mobile_items-number">4.2.</span> <span class="toc_mobile_items-text">Span Filtering</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Relation-Classification"><span class="toc_mobile_items-number">4.3.</span> <span class="toc_mobile_items-text">Relation Classification</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#实验"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">实验</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#总结"><span class="toc_mobile_items-number">6.</span> <span class="toc_mobile_items-text">总结</span></a></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#摘要"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#介绍"><span class="toc-number">2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#相关工作"><span class="toc-number">3.</span> <span class="toc-text">相关工作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Joint-Entity-and-Relation-Extraction"><span class="toc-number">3.1.</span> <span class="toc-text">Joint Entity and Relation Extraction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Span-based-Approaches"><span class="toc-number">3.2.</span> <span class="toc-text">Span-based Approaches</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#模型架构"><span class="toc-number">4.</span> <span class="toc-text">模型架构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Span-Classification"><span class="toc-number">4.1.</span> <span class="toc-text">Span Classification</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Span-Filtering"><span class="toc-number">4.2.</span> <span class="toc-text">Span Filtering</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Relation-Classification"><span class="toc-number">4.3.</span> <span class="toc-text">Relation Classification</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实验"><span class="toc-number">5.</span> <span class="toc-text">实验</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-number">6.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://img-blog.csdnimg.cn/2020071920490854.png)"><div id="post-info"><div id="post-title"><div class="posttitle">【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-08-10<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-08-10</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%88%98%E5%A6%82%E6%84%8F/">刘如意</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%88%98%E5%A6%82%E6%84%8F/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/">信息抽取</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">2.6k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 8 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><p><a href="https://img-blog.csdnimg.cn/2020071920490854.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/2020071920490854.png" class="lazyload"></a><br>论文链接：<a href="https://arxiv.org/abs/1909.07755" target="_blank" rel="noopener">https://arxiv.org/abs/1909.07755</a><br>论文代码：<a href="https://github.com/markus-eberts/spert" target="_blank" rel="noopener">https://github.com/markus-eberts/spert</a></p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>&emsp;&emsp;我们引入了一个用于基于spaner的联合实体和关系提取的关注模型 SpERT。我们的关键贡献是对BERT嵌入的轻量级推理，其特征是实体识别和过滤，以及使用本地化的、无标记上下文表示的关系分类。该模型使用强句内负样本进行训练，这些负样本在单次BERT中被有效地提取出来。这些方面促进了对句子中所有跨度的搜索。在消融研究中，我们证明了预训练、强负采样和局部环境的好处。在联合实体和关系提取方面，我们的模型在几个数据集上的表现比之前的工作高出2.6% F1分。 </p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>&emsp;&emsp;提出了一种以变压器网络BERT为核心的联合实体和关系提取模型。采用基于span的方法:任何标记子序列(或span)构成一个潜在的实体，任何一对span之间都可以保持关系。我们的模型对所有这些假设进行了全面的搜索。与之前基于BIO/BILOU标签的研究不同基于spanbased的方法可以在“可待因中毒”中识别重叠的实体，如“可待因”。由于变压器模型像伯特计算昂贵,我们的方法只进行一个传球前进每输入句子并执行一个轻量级的推理结果嵌入,与近期其他方法,我们的模型特征一个简单得多的下游加工使用浅实体/关系分类器。我们使用不使用特定标记的本地上下文表示，并在单个BERT传递中从相同的句子中提取负样本。这些方面促进了有效的培训和全方位的搜索。我们创建了模型“基于span基实体和关系转换器”(SpERT)。总而言之，我们的贡献如下:</p>
<ul>
<li>提出了一种基于spans的联合实体和关系的提取方法。我们的方法看似简单但有效，始终比之前的工作多出2.6%(关系提取F1得分)</li>
<li>我们调查了几个对我们的模型成功至关重要的方面，表明(1)来自同一个句子的负样本产生的训练是既高效又有效的，而且足够多的强负样本显得至关重要。(2)局部上下文表示是有益的，特别是对于较长的句子。(3)我们还研究了预训练的效果，表明对预训练模型进行微调，比从零开始训练的效果更好。</li>
</ul>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><h2 id="Joint-Entity-and-Relation-Extraction"><a href="#Joint-Entity-and-Relation-Extraction" class="headerlink" title="Joint Entity and Relation Extraction"></a>Joint Entity and Relation Extraction</h2><p>&emsp;&emsp;由于实体检测和关系分类可能受益于利用相互关联的信号，联合检测实体和关系的模型最近引起关注(例[3,2,21,31,40,16])。大多数方法通过序列到序列学习来检测实体:每个标记都根据众所周知的BIO方案(或其BILOU变体)进行标记。与我们的工作更相似的是Li等人[18]最近的方法，他们也将BERT作为他们的核心模型，并使用一个问题回答设置，其中实体和关系特定的问题引导模型的头和尾实体。该模型需要每个关联手动定义(伪)问题模板，例如“找到[?]拥有的武器”。实体通过基于BERT嵌入的基于双侧类型标记的关系标记来检测。与此方法相反，我们的模型不需要明确的问题表述。此外，我们的方法是基于span-based而不是BILOU。</p>
<h2 id="Span-based-Approaches"><a href="#Span-based-Approaches" class="headerlink" title="Span-based Approaches"></a>Span-based Approaches</h2><p>&emsp;&emsp;最近，一些针对联合实体和关系提取的基于span-based模型被提出[20,9]，使用来自于连接ELMo的BiLSTM的span表示，单词和字符嵌入。然后在下游任务之间共享这些表示。Dixit和al - onaizan[9]侧重于联合实体和关系提取，Luan等[20]对假设空间进行波束搜索，估计参与实体类、关系和共参照的跨度。Luan等人的后续模型DyGIE[21]增加了一个图传播步骤来捕捉跨度的相互作用。构造了一个动态跨度图，在此图中使用学习的门控机制传播嵌入。使用这种细化的跨度表示，进一步的改进被证明。最近，Wadden等人的DyGIE++[34]已经用BERT取代了BiLSTM编码器。DyGIE++是唯一的基于变流器的跨度方法，用于联合实体和关系的提取。与DyGIE和DyGIE++相比，我们的模型使用了更简单的下游处理，省略了任何图传播，使用了较浅的实体和关系分类器。相反，我们发现局部上下文表示和强负抽样至关重要。我们在实验部分加入了与DyGIE++的定量比较。</p>
<h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><p>&emsp;&emsp;模型主要由 span classification 、 Span Filtering 和 relation classification 三部分组成。 span classification 和 Span Filtering 对实体进行筛选和识别，relation classification 进行关系抽取。模型架构如图所示：</p>
<p><a href="https://img-blog.csdnimg.cn/20200719212234770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200719212234770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" class="lazyload"></a></p>
<h2 id="Span-Classification"><a href="#Span-Classification" class="headerlink" title="Span Classification"></a>Span Classification</h2><p>&emsp;&emsp;我们的span分类器采用一个任意的候选span作为输入。设s:= (ei,ei+1，…，ei+k)表示该张成空间。此外，我们假设E是一组预定义的实体类别，如person或organization。span分类器将span s映射到E∪{none}中的一个类。none表示不构成实体的跨度。span分类器的详细信息显示在图1的虚线框中。它的投入包括三个部分:</p>
<ul>
<li>张成空间的BERT嵌入(红色)使用融合f(ei,ei+1，…，ei+k)组合。对于融合函数f，我们发现max-pooling的效果最好，但将在实验中研究其他选项</li>
<li>给定跨度宽度k+1，我们从一个专用的嵌入矩阵中查找一个宽度嵌入wk+1(蓝色)，它包含一个固定大小的嵌入，每个跨度宽度为1,2，…[14]。这些嵌入是通过反向传播来学习的，并且允许模型在跨度宽度上合并一个先验(注意跨度太长不太可能表示实体)。</li>
</ul>
<h2 id="Span-Filtering"><a href="#Span-Filtering" class="headerlink" title="Span Filtering"></a>Span Filtering</h2><p>&emsp;&emsp;通过查看得分最高的类，跨度分类器的输出(方程3)估计了每个跨度属于哪个类。我们使用一种简单的方法过滤分配给none类的所有span，只留下一组spans，它们可能构成实体。注意不像以前的工作这次是没有对实体/关系假设执行光束搜索。我们预先过滤跨度超过10个标记，将跨度分类的代价限制在O(n)。</p>
<h2 id="Relation-Classification"><a href="#Relation-Classification" class="headerlink" title="Relation Classification"></a>Relation Classification</h2><p>&emsp;&emsp;设R是一组预定义的关系类。关系分类器处理从S×S中抽取的实体的每个候选对(s1, s2)，并估计是否存在来自R的关系。分类器的输入包括两部分:</p>
<ul>
<li>为了表示两个候选实体s1、s2，我们使用融合的BERT/width embeddings e(s1)，e(s2) (Eq. 1)。</li>
<li>显然，上下文中的词汇，如配偶或总统，是表达关系的重要指标。一种可能的上下文表示方法是分类器标记c。然而，我们发现c不适用于表达多种关系的长句子。相反，我们使用从实体的直接周围提取的更本地化的上下文:给定从第一个实体结束到第二个实体开始的范围(图1，黄色)，我们通过最大池化将其BERT嵌入组合起来，获得上下文表示c(s1, s2)。如果范围是空的(例如，在重叠实体的情况下)，我们设置c(s1, s2) = 0。</li>
</ul>
<p>&emsp;&emsp;除了实体特征以外，关系抽取也要依赖文本特征。由于特殊标记CLS有文本分类的作用，关系抽取的模型架构往往会使用CLS所代表的词向量作为关系抽取的输入之一。而在本文中，并没有选择CLS作为文本特征，而是对于两个实体之间的文本进行了最大池化 ，得到了文本特征的向量表示 c(s1,s2) 也就是模型图中黄色的部分。如果两个实体之间没有文本，那么 c(s1,s2) \mathbf  将被设置为0 。<br>&emsp;&emsp;至此，我们得到了关系的向量表示，由于关系往往是非对称的，所以每一个实体对将会得到两个关系表示。公式如下：</p>
<p><a href="https://img-blog.csdnimg.cn/20200719213824460.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200719213824460.png" class="lazyload"></a><br>&emsp;&emsp;接下来这两个关系将会过一个全连接后再用一个sigmoid激活，公式如下：<a href="https://img-blog.csdnimg.cn/20200719213844199.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200719213844199.png" class="lazyload"></a></p>
<p>&emsp;&emsp;最后，模型的损失是实体分类损失与关系分类损失之和，公式如下：<br><a href="https://img-blog.csdnimg.cn/20200719213935805.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200719213935805.png" class="lazyload"></a></p>
<p>&emsp;&emsp;至此，模型整体的架构已经比较清楚了。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>&emsp;&emsp;将SpERT与其他联合实体/关系提取模型进行了比较，并研究了多个超参数的影响。评估是在ADE、CoNLL04和SciERC三个公开的数据集上进行的。</p>
<p><a href="https://img-blog.csdnimg.cn/20200719214119807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200719214119807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" class="lazyload"></a><br><a href="https://img-blog.csdnimg.cn/20200719214133545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200719214133545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" class="lazyload"></a><br><a href="https://img-blog.csdnimg.cn/20200719214142215.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200719214142215.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" class="lazyload"></a></p>
<p>&emsp;&emsp;虽然SpERT在联合实体和关系提取方面取得了很好的结果，但我们观察到一些常见的错误，这为进一步的研究留下了空间。<br><a href="https://img-blog.csdnimg.cn/20200719214406472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" title="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200719214406472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY4NDQwOA==,size_16,color_FFFFFF,t_70" class="lazyload"></a></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;我们提出了一个基于spans的联合实体和关系提取模型SpERT，它以预先训练好的变压器网络BERT为核心。我们证明，通过强负抽样、跨度过滤和本地化上下文表示，在输入句子中搜索所有跨度成为可行的。我们的结果表明，基于spanbased的方法与基于bilo的模型相比具有竞争力，并且由于其识别重叠实体的能力，可能是未来研究中更有前途的方法。在将来，我们计划为关系分类器研究更精细的上下文形式。目前，我们的模型只是使用了两个实体之间的跨度，这被证明比整个上下文更好。使用额外的语法特性或学习的上下文——同时保持高效的穷举搜索——似乎是一个有希望的挑战。</p>
<p>原文链接： <a href="https://blog.csdn.net/weixin_45684408/article/details/107451219" target="_blank" rel="noopener">【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training</a>.</p>
</div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NLP/">NLP    </a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习    </a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文    </a><a class="post-meta__tags" href="/tags/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/">信息抽取    </a></div><div class="post_share"></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/08/10/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%80%BB%E4%BD%93%E6%9E%84%E5%BB%BA%E6%80%9D%E8%B7%AF%EF%BC%88%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%EF%BC%89/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.8/img/张明磊/8.10/1.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>知识图谱总体构建思路（非结构化文本数据）</span></div></a></div><div class="next-post pull_right"><a href="/2020/08/09/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1(%E4%B8%80)%EF%BC%9A%E6%A6%82%E8%BF%B0/"><img class="next_cover lazyload" data-src="https://img-blog.csdnimg.cn/20200809113542976.png#pic_center" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>知识图谱(一)：概述</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/01/【论文阅读笔记PCNN】Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks/" title="【论文阅读笔记PCNN】Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200801134611553.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-01</div><div class="relatedPosts_title">【论文阅读笔记PCNN】Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/分类任务评价指标/" title="分类任务评价指标"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/zhengguanyu/PhotoRepos@v1.1/img/封面.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">分类任务评价指标</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/04/论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》/" title="论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200803210957976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-04</div><div class="relatedPosts_title">论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/论文阅读：Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks/" title="论文阅读：Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.5/img/朱鑫海/8.2/1.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">论文阅读：Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/传统的机器学习方法——决策树（上）/" title="传统的机器学习方法——决策树（上）"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200802172055879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">传统的机器学习方法——决策树（上）</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/09/传统的机器学习方法——决策树（下）/" title="传统的机器学习方法——决策树（下）"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200809164842535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-09</div><div class="relatedPosts_title">传统的机器学习方法——决策树（下）</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By 东北石油大学智能技术与自然语言处理实验室</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">欢迎来到我们团队的博客！</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>