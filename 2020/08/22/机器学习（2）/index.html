<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>机器学习（2） | 东北石油大学智能技术与自然语言处理实验室</title><meta name="description" content="机器学习（2）"><meta name="keywords" content="机器学习,自然语言处理,算法"><meta name="author" content="东北石油大学智能技术与自然语言处理实验室"><meta name="copyright" content="东北石油大学智能技术与自然语言处理实验室"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/ava.jpg"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="机器学习（2）"><meta name="twitter:description" content="机器学习（2）"><meta name="twitter:image" content="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/训练误差与测试误差.jpg"><meta property="og:type" content="article"><meta property="og:title" content="机器学习（2）"><meta property="og:url" content="https://nlplab406.github.io/2020/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%882%EF%BC%89/"><meta property="og:site_name" content="东北石油大学智能技术与自然语言处理实验室"><meta property="og:description" content="机器学习（2）"><meta property="og:image" content="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/训练误差与测试误差.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://nlplab406.github.io/2020/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%882%EF%BC%89/"><link rel="next" title="分治法刷题总结" href="https://nlplab406.github.io/2020/08/20/%E5%88%86%E6%B2%BB%E6%B3%95%E5%88%B7%E9%A2%98%E6%80%BB%E7%BB%93/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: true,
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">东北石油大学智能技术与自然语言处理实验室</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/ava.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">27</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">30</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">31</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#机器学习（2）"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">机器学习（2）</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#模型的评估与选择笔记（1）"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">模型的评估与选择笔记（1）</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#基本术语"><span class="toc_mobile_items-number">1.1.1.</span> <span class="toc_mobile_items-text">基本术语</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#训练误差与测试误差"><span class="toc_mobile_items-number">1.1.1.1.</span> <span class="toc_mobile_items-text">训练误差与测试误差</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#训练误差是模型关于训练数据集的平均损失："><span class="toc_mobile_items-number">1.1.1.1.1.</span> <span class="toc_mobile_items-text">训练误差是模型关于训练数据集的平均损失：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#测试误差是模型关于测试数据集的平均损失："><span class="toc_mobile_items-number">1.1.1.1.2.</span> <span class="toc_mobile_items-text">测试误差是模型关于测试数据集的平均损失：</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#差错率"><span class="toc_mobile_items-number">1.1.1.2.</span> <span class="toc_mobile_items-text">差错率</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#准确率"><span class="toc_mobile_items-number">1.1.1.3.</span> <span class="toc_mobile_items-text">准确率</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#经验误差和过拟合"><span class="toc_mobile_items-number">1.1.2.</span> <span class="toc_mobile_items-text">经验误差和过拟合</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#拟合结果"><span class="toc_mobile_items-number">1.1.2.1.</span> <span class="toc_mobile_items-text">拟合结果</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#评估方法"><span class="toc_mobile_items-number">1.1.3.</span> <span class="toc_mobile_items-text">评估方法</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#留出法"><span class="toc_mobile_items-number">1.1.3.1.</span> <span class="toc_mobile_items-text">留出法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#交叉验证法"><span class="toc_mobile_items-number">1.1.3.2.</span> <span class="toc_mobile_items-text">交叉验证法</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#数据充足的情况下："><span class="toc_mobile_items-number">1.1.3.2.1.</span> <span class="toc_mobile_items-text">数据充足的情况下：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#数据不充足的情况下："><span class="toc_mobile_items-number">1.1.3.2.2.</span> <span class="toc_mobile_items-text">数据不充足的情况下：</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#简单交叉验证：随机数据分为两部分，即训练集和测试集"><span class="toc_mobile_items-number">1.1.3.2.2.1.</span> <span class="toc_mobile_items-text">简单交叉验证：随机数据分为两部分，即训练集和测试集</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#S折交叉验证：随即将数据分为S个互不相交，大小不同的子集，其中S-1个子集作为训练集，余下的子集作为测试集。"><span class="toc_mobile_items-number">1.1.3.2.2.2.</span> <span class="toc_mobile_items-text">S折交叉验证：随即将数据分为S个互不相交，大小不同的子集，其中S-1个子集作为训练集，余下的子集作为测试集。</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#留一交叉验证：S折交叉验证的特殊情形，S-N（N是指数据集的样本容量）"><span class="toc_mobile_items-number">1.1.3.2.2.3.</span> <span class="toc_mobile_items-text">留一交叉验证：S折交叉验证的特殊情形，S&#x3D;N（N是指数据集的样本容量）</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#自助法"><span class="toc_mobile_items-number">1.1.3.3.</span> <span class="toc_mobile_items-text">自助法</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#总结："><span class="toc_mobile_items-number">1.1.4.</span> <span class="toc_mobile_items-text">总结：</span></a></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#机器学习（2）"><span class="toc-number">1.</span> <span class="toc-text">机器学习（2）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#模型的评估与选择笔记（1）"><span class="toc-number">1.1.</span> <span class="toc-text">模型的评估与选择笔记（1）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基本术语"><span class="toc-number">1.1.1.</span> <span class="toc-text">基本术语</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#训练误差与测试误差"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">训练误差与测试误差</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#训练误差是模型关于训练数据集的平均损失："><span class="toc-number">1.1.1.1.1.</span> <span class="toc-text">训练误差是模型关于训练数据集的平均损失：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#测试误差是模型关于测试数据集的平均损失："><span class="toc-number">1.1.1.1.2.</span> <span class="toc-text">测试误差是模型关于测试数据集的平均损失：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#差错率"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">差错率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#准确率"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">准确率</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#经验误差和过拟合"><span class="toc-number">1.1.2.</span> <span class="toc-text">经验误差和过拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#拟合结果"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">拟合结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#评估方法"><span class="toc-number">1.1.3.</span> <span class="toc-text">评估方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#留出法"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">留出法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#交叉验证法"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">交叉验证法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#数据充足的情况下："><span class="toc-number">1.1.3.2.1.</span> <span class="toc-text">数据充足的情况下：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#数据不充足的情况下："><span class="toc-number">1.1.3.2.2.</span> <span class="toc-text">数据不充足的情况下：</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#简单交叉验证：随机数据分为两部分，即训练集和测试集"><span class="toc-number">1.1.3.2.2.1.</span> <span class="toc-text">简单交叉验证：随机数据分为两部分，即训练集和测试集</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#S折交叉验证：随即将数据分为S个互不相交，大小不同的子集，其中S-1个子集作为训练集，余下的子集作为测试集。"><span class="toc-number">1.1.3.2.2.2.</span> <span class="toc-text">S折交叉验证：随即将数据分为S个互不相交，大小不同的子集，其中S-1个子集作为训练集，余下的子集作为测试集。</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#留一交叉验证：S折交叉验证的特殊情形，S-N（N是指数据集的样本容量）"><span class="toc-number">1.1.3.2.2.3.</span> <span class="toc-text">留一交叉验证：S折交叉验证的特殊情形，S&#x3D;N（N是指数据集的样本容量）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#自助法"><span class="toc-number">1.1.3.3.</span> <span class="toc-text">自助法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#总结："><span class="toc-number">1.1.4.</span> <span class="toc-text">总结：</span></a></li></ol></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/训练误差与测试误差.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">机器学习（2）</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-08-22<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-08-22</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%A9%B9%E5%AD%90%E4%BE%9D/">詹子依</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%A9%B9%E5%AD%90%E4%BE%9D/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">4.5k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 13 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="机器学习（2）"><a href="#机器学习（2）" class="headerlink" title="机器学习（2）"></a>机器学习（2）</h1><h2 id="模型的评估与选择笔记（1）"><a href="#模型的评估与选择笔记（1）" class="headerlink" title="模型的评估与选择笔记（1）"></a>模型的评估与选择笔记（1）</h2><p>&emsp;&emsp;<em>这篇文章是根据周志华老师西瓜书的相关内容以及网上一些相关资料的查询，进而理解总结的笔记。如果还有不足的地方，希望大家能够指出，一起学习和讨论。</em></p>
<h3 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h3><blockquote>
<p>首先是要讲的是训练误差与泛化误差（测试误差）的相关内容的一些术语：</p>
<p>•通常我们把<u>分类错误的样本数占样本总数的比例</u>称为<strong>错误率</strong>，即如果在m个样本中有a个样本分类错误，则<strong>错误率E=a/m</strong></p>
<p>•相应的<u>1-a/m</u>称为<strong>精度（准确率）</strong>，即<u>精度（准确率）=1-错误率</u></p>
<p>•更一般的我们把学习器的<u>实际预测输出与样本真实输出之间的差异</u>称为“<strong>误差</strong>”</p>
<p>•学习器在<u>训练集上的误差</u>称为<strong>训练误差或经验误差</strong>。</p>
<p>•在<u>新样本上的误差</u>称为<strong>泛化误差</strong>。</p>
<p>•通常，我们可以通过实验测试来对学习器的泛化误差进行评估并作出选择，为此，需要<u>一个测试集来测试学习器对新样本的判别能力</u>，然后<u>以测试集上的</u><strong>测试误差</strong>来作为<u>泛化误差的近似</u>。</p>
</blockquote>
<h4 id="训练误差与测试误差"><a href="#训练误差与测试误差" class="headerlink" title="训练误差与测试误差"></a>训练误差与测试误差</h4><p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/训练误差与测试误差.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="16" class="fancybox"><img alt="16" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/训练误差与测试误差.jpg" class="lazyload" title="16"></a></p>
<p>&emsp;&emsp;现在我们来具体理解一下训练误差与测试误差，以上是监督学习的一个流程图：</p>
<p>&emsp;&emsp;假如存在样本容量为N的训练集:(x1,x2)…(xN,YN),我们将训练集输入到学习系统里面，可以训练学习得到一个模型。我们将这个模型用决策函数的形式来表达:</p>
<script type="math/tex; mode=display">
y=\hat{f}(x)</script><p>&emsp;&emsp;那么关于这个模型的<u>拟合</u>的好坏可以<u>通过训练集计算训练误差</u>进行衡量，而关于这个模型的<u>预测效果</u>，也就是它对未知数据的预测能力的好坏，可以通过<u>测试集</u><u>计算测试误差</u>来衡量。假如存在一个样本容量为N‘的测试集，我们将测试集<u>所有的输入</u>都放入预测系统里，通过得到的模型，可以得到一系列的预测值，如图右下角。那么这些预测值与真实值之间的差异，我们可以计算得到<u>测试误差</u>，测试误差可以衡量模型的预测效果了。</p>
<h5 id="训练误差是模型关于训练数据集的平均损失："><a href="#训练误差是模型关于训练数据集的平均损失：" class="headerlink" title="训练误差是模型关于训练数据集的平均损失："></a><strong>训练误差</strong>是<u>模型关于训练数据集的</u>平均损失：</h5><p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/Screenshot_20200811-160023.png" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/Screenshot_20200811-160023.png" class="lazyload" title></a></p>
<p>&emsp;&emsp;从图中我们可以看到它是先计算了每个样本（所有的样本来自训练集）的损失，再求它们的平均损失。</p>
<h5 id="测试误差是模型关于测试数据集的平均损失："><a href="#测试误差是模型关于测试数据集的平均损失：" class="headerlink" title="测试误差是模型关于测试数据集的平均损失："></a>测试误差是模型关于测试数据集的平均损失：</h5><p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821170948.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="15" class="fancybox"><img alt="15" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821170948.jpg" class="lazyload" title="15"></a></p>
<p>&emsp;&emsp;于是我们可以看到，当损失函数是0-1损失时，测试误差就变成了常见的测试数据集上的误差率（差错率）。</p>
<h4 id="差错率"><a href="#差错率" class="headerlink" title="差错率"></a>差错率</h4><p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821171239.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="11" class="fancybox"><img alt="11" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821171239.jpg" class="lazyload" title="11"></a></p>
<p>&emsp;&emsp;这里I是指示函数，即y≠f^(x)时为1，否则为0</p>
<h4 id="准确率"><a href="#准确率" class="headerlink" title="准确率"></a>准确率</h4><p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821171243.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="12" class="fancybox"><img alt="12" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821171243.jpg" class="lazyload" title="12"></a></p>
<p>&emsp;&emsp;于是有：<br><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821171246.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="14" class="fancybox"><img alt="14" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821171246.jpg" class="lazyload" title="14"></a></p>
<h3 id="经验误差和过拟合"><a href="#经验误差和过拟合" class="headerlink" title="经验误差和过拟合"></a>经验误差和过拟合</h3><blockquote>
<p>显然，我们希望得到泛化误差小的学习器，但我们事先不知道新样本是什么样，实际能做的就是努力使经验误差最小化。</p>
<p>在很多情况下，我们可以学得一个<u>经验误差（训练误差）很小，在训练集上表现很好</u>的学习器。<u>例如甚至对所有的训练样本都分类正确，即分类错误率为零，分类精度为100%</u>，但这样的<u>学习器在多数情况下都不好</u>。</p>
<p>•我们实际希望的，是在新样本上能表现得很好的学习器。为了达到这个目的，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”，这样才能在遇到新样本时做出正确的判别。然而<u>当学习器把训练样本学的太好的时候，很可能把训练样本自身的一些特点（不是共性的东西）当作了潜在样本都会具有的一般品质，这样会导致泛化性能下降。这种现象在机器学习中称为过拟合。</u></p>
<p>•那么相对的就是欠拟合，这是指<u>对训练样本的一般性质尚未学好</u>。（那么它泛化的时候，测试的时候也很差。）</p>
</blockquote>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/6666666666.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="10" class="fancybox"><img alt="10" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/6666666666.jpg" class="lazyload" title="10"></a></p>
<blockquote>
<p>•有很多种因素可能导致过拟合，其中最常见的情况是由于学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了，而欠拟合则通常是由于学习能力低下而造成的。<u>欠拟合比较容易克服，例如在决策树中扩展分支，在神经网络中增加训练轮数等</u>。</p>
<p>•而过拟合则很麻烦，在后面的学习中我们将看到，<u>过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一些针对拟合的措施；然而必须认识到，过拟合是无法彻底避免的，我们所能做的只是“缓解”，或者说减小风险。</u></p>
</blockquote>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821175904.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="9" class="fancybox"><img alt="9" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821175904.jpg" class="lazyload" title="9"></a></p>
<p>&emsp;&emsp;如图，黑色的曲线是真实的函数，蓝色的点是我们得到的用来作为训练集的十个样本点。</p>
<p>&emsp;&emsp;下面，我们通过M次多项式这些的数据进行拟合，即假设给定的数据是M次多项式生成的。这里M代表最高次数，W是参数向量。如果此时，M=0，那么f=W0，那么拟合的曲线就是平行于x轴的一条直线。当M=1的时候，f=W0+W1x,此时拟合的曲线就是一条直线，斜率项是W1，截距项是W0，而M=2时，拟合的曲线就是一个二次曲线等等。</p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821233715.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="8" class="fancybox"><img alt="8" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821233715.jpg" class="lazyload" title="8"></a></p>
<p>&emsp;&emsp;我们在拟合的时候采取一个经验风险最小化策略，这里经验风险用的损失函数是平方损失，也就是预测值与真实值差的平方，经验风险就是每个样本点的平方损失的和。对于经验风险最小化，我们可以通过最小二乘法求解参数，即通过对经验风险中的W进行求导，使导数等于0，得到参数的表达式。（加1/2是在求导中计算方便，不影响最后结果）</p>
<h4 id="拟合结果"><a href="#拟合结果" class="headerlink" title="拟合结果"></a>拟合结果</h4><p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821235243.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="7" class="fancybox"><img alt="7" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200821235243.jpg" class="lazyload" title="7"></a></p>
<p>&emsp;&emsp;这里分别选择了M=0,M=1,M=3,M=9的结果。M=0的时候，拟合曲线就是平行于x轴的直线，这时候它与真实曲线差异很大，显然，此时的训练误差也是很大的。M=1的时候，拟合曲线是一条直线，相比较M=0，接近了真实的曲线。M=3的时候，拟合的曲线与真实的曲线是非常接近的。M=9的时候，拟合曲线通过了所有的样本点，此时训练误差几乎为0。但是M=9是一个过拟合的现象。</p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822000342.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="6" class="fancybox"><img alt="6" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822000342.jpg" class="lazyload" title="6"></a></p>
<p>（图省略了M=9的情况，此时训练误差几乎为0，而测试误差非常大，远远超出这个图）</p>
<p>&emsp;&emsp;我们用M代表了模型的复杂度，M越大，模型越复杂。（橙色的线代表测试误差：模型对未知数据的预测能力；蓝色代表训练误差：模型对已知数据的预测能力）当M=1的时候，训练误差和测试误差都比较大，而随着模型复杂度的增加，训练误差和测试误差都在减小。而达到3的时候，此时测试误差达到最小，训练误差也达到一个较小的情况。而随着模型复杂度的不断增加，训练误差会继续减小，而测试误差会随着复杂度的增加而增大。即当M&gt;3的时候，模型会对已知数据预测越来越好，未知数据预测越来越差。我们希望训练误差和测试误差达到一个平衡，即M=3的这个点。即选模型的时候，选择测试误差与训练误差都比较小的点。</p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822001544.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="5" class="fancybox"><img alt="5" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822001544.jpg" class="lazyload" title="5"></a></p>
<p>&emsp;&emsp;所以我们选择模型的时候一定要避免过拟合的情况，选择适当的模型复杂度，使训练误差和测试误差都达到比较小的模型。</p>
<h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h3><blockquote>
<p><u>测试集应尽量与训练集互斥，即测试样本尽量不在训练集中出现，未在训练过程中使用过</u>。</p>
<p>老师出了10道习题供同学们练习，考试时老师又用同样的10道题作为试题，这个考试成绩能否有效反映出同学们学的好不好呢？答案是否定的，可能有的同学只会做10道题而拿高分。回到我们的问题上来，我们希望得到泛化性强的模型，好比是希望同学们对课程学的好，达到了举一反三的能力；训<u>练样本相当于给同学们练习的习题，测试过程相当于考试，显然，若测试样本被用作训练了，得到的则是过于乐观的结果。</u></p>
<p>可是我们只有一个包含m个样例的数据集D={(x1,y1)…(xm,ym)},既要训练，又要测试，怎样才能做到呢。</p>
<p>答案是：对D进行适当的处理，从中产出训练集S和测试集T。</p>
</blockquote>
<h4 id="留出法"><a href="#留出法" class="headerlink" title="留出法"></a>留出法</h4><blockquote>
<p><u>留出法是直接将数据集D划分为互斥的两个集合</u>，其中一个集合作为训练集S，另一个作为测试集T，即D=SUT,S∩T=空集。在S训练出模型后，用T来评估其测试误差，作为对泛化误差的估计。</p>
<p>以二分类任务为例，假定D包含1000个样本，将其划分为S包含700个样本，T包含300个样本，用S训练后，如果T上有90个样本分类错误，那么错误率就是（90/300）x100%=30%，相应的，精度为1-30%=70%</p>
<p>需注意的是,<u>训练/测试集的划分要尽可能保持数据分布的一致性</u>,避免因数据划分过程引入额外的偏差而对最终结果产生影响,例如在分类任务中至少<u>要保持样本的类别比例相似</u>.如果从采样(sampling)的角度来看待数据集的划分过程，则<u>保留类别比例的采样方式</u>通常称为“<strong>分层采样</strong>”(stratifiedsampling).</p>
</blockquote>
<p>&emsp;&emsp;比如D有100个样本，A类有50个，B类有50个。将100个样本，80个作为训练，20个作为测试。</p>
<p>&emsp;&emsp;那么训练/测试集划分保持一致性就是：划分训练集80个样本和测试集20个样本之后，在它们之中也要保证A和B两类的数据也是50%：50%的分布。</p>
<p>&emsp;&emsp;即80个样本里，A类40个，B类40个。20个样本里，A类10个，B类10个。这样测试集的分布情况和训练集的分布情况与整体的分布情况是一致的。那么“至少要保证样本类别比例相似”是说，比如这训练集80个样本里，A类42个，B类38个，也是完全可以的，在比例上变化是不大的。但是差距太大就不行，比如训练集80个样本里，A类30个，B类50个。则在测试集20个样本里，A类就是20个，B类为0个。</p>
<p>&emsp;&emsp;所以用分层采样的方法，保证测试集/训练集的分布与整体保持一致。</p>
<blockquote>
<p>例如通过对D进行分层采样而获得含70%样本的训练集S和含30%样本的测试集T,若D包含500个正例、500个反例，则分层采样得到的S应包含350个正例、350 个反例,而T则包含150个正例和150个反例;若S、T中样本类别比例差别很大,则误差估计将由于训练/测试数据分布的差异而产生偏差。</p>
<p>另一个需注意的问题是,即便在给定训练/测试集的样本比例后，<u>仍存在多种划分方式对初始数据集D进行分割</u>。例如在上面的例子中，可以把D中的样本排序,然后把<u>前350个正例放到训练集中，也可以把最后350个正例放到训练集中</u>，….这些不同的划分将导致不同的训练/测试集,相应的,模型评估的结果也会有差别.因此，<u>单次使用留出法得到的估计结果往往不够稳定可靠</u>,在使用留出法时，<u>一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果</u>.例如进行100次随机划分，每次产生-一个训练/测试集用于实验评估, 100次后就得到100个结果,而留出法返回的则是这100个结果的平均。</p>
<p>常见的作法是将大约2/3~4/5的样本用于训练，剩余样本用于测试。（但是如果是非常大的数据，就不用取2/3~4/5，取1/5或者更小的比例来取样本作为训练。根据实际需要。）</p>
</blockquote>
<h4 id="交叉验证法"><a href="#交叉验证法" class="headerlink" title="交叉验证法"></a>交叉验证法</h4><h5 id="数据充足的情况下："><a href="#数据充足的情况下：" class="headerlink" title="数据充足的情况下："></a>数据充足的情况下：</h5><p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822113447.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822113447.jpg" class="lazyload" title="3"></a></p>
<p>&emsp;&emsp;训练集：用以训练模型</p>
<p>&emsp;&emsp;验证集：用以选择模型</p>
<p>&emsp;&emsp;测试集：用以最终对学习方法的评估</p>
<p>&emsp;&emsp;通常假设验证集里有足够多的数据，通过训练集训练的模型放入验证集里面，选择预测误差最小的那个就是我们的最优模型。</p>
<h5 id="数据不充足的情况下："><a href="#数据不充足的情况下：" class="headerlink" title="数据不充足的情况下："></a>数据不充足的情况下：</h5><p>&emsp;&emsp;交叉验证的思想就是重复使用数据，以解决数据不足的情况。</p>
<h6 id="简单交叉验证：随机数据分为两部分，即训练集和测试集"><a href="#简单交叉验证：随机数据分为两部分，即训练集和测试集" class="headerlink" title="简单交叉验证：随机数据分为两部分，即训练集和测试集"></a>简单交叉验证：随机数据分为两部分，即训练集和测试集</h6><p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822114145.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822114145.jpg" class="lazyload" title="1"></a></p>
<h6 id="S折交叉验证：随即将数据分为S个互不相交，大小不同的子集，其中S-1个子集作为训练集，余下的子集作为测试集。"><a href="#S折交叉验证：随即将数据分为S个互不相交，大小不同的子集，其中S-1个子集作为训练集，余下的子集作为测试集。" class="headerlink" title="S折交叉验证：随即将数据分为S个互不相交，大小不同的子集，其中S-1个子集作为训练集，余下的子集作为测试集。"></a>S折交叉验证：随即将数据分为S个互不相交，大小不同的子集，其中S-1个子集作为训练集，余下的子集作为测试集。</h6><p>&emsp;&emsp;假如S=10，我们看下图的这个例子：我们可以将数据集均匀的分为T1…T10 这10个子集，以其中9个子集作为训练集，在测试集里计算测试误差。这样可以获得10组训练/测试集，从而可以进行10次训练和测试，最终返回的是这10个测试结果的均值。</p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822114649.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822114649.jpg" class="lazyload" title="2"></a></p>
<p>&emsp;&emsp;与留出法相似，将数据集D划分为S个子集同样存在多种划分方式。为减小因样本划分不同而引入的差别，S折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次S折交叉验证结果的均值，例如常见的“10次10折交叉验证”</p>
<h6 id="留一交叉验证：S折交叉验证的特殊情形，S-N（N是指数据集的样本容量）"><a href="#留一交叉验证：S折交叉验证的特殊情形，S-N（N是指数据集的样本容量）" class="headerlink" title="留一交叉验证：S折交叉验证的特殊情形，S=N（N是指数据集的样本容量）"></a>留一交叉验证：S折交叉验证的特殊情形，S=N（N是指数据集的样本容量）</h6><p>&emsp;&emsp;这时候是在数据非常不足的情况下使用的。</p>
<blockquote>
<p>假定数据集D包含m个样本，若令S=m，则得到了交叉验证的一个特例：留一法。显然，这种方法不受随机样本划分的影响；因为m个样本只有唯一的方式划分为m个子集—每个子集包含一个样本；留一法使用的训练集与初始数据集相比只少了一个样本，这就使得在大多数情况下，留一法中被实际评估得模型与期望评估的用D训练出的模型很相似，因此，留一法的评估结果往往被认为准确。但这是在数据集比较小的情况下使用的。当然，留一法也未必永远比其他方法评估准确。“没有免费午餐“定理对实验评估方法同样适用。</p>
</blockquote>
<h4 id="自助法"><a href="#自助法" class="headerlink" title="自助法"></a>自助法</h4><p>&emsp;&emsp;模型评估中，自助法的思路是这样的：原数据集D是一个包含m个样本的数据集，通过自助法有放回的重复抽样m次，每次抽取1个数据，放到D’中，D’中也有m个样本，同时，原来的数据集D中不被D’包含的数据作为测试集。D’做训练集。</p>
<p>&emsp;&emsp;可做一个简单的估计：样本在m次采样中始终不会被采到的概率是（1-1/m)^m,取极限可以得到：</p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822131825.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/微信图片_20200822131825.jpg" class="lazyload" title></a></p>
<p>&emsp;&emsp;即通过自助采样，初始数据集D中有36.8%的样本未出现在采样数据集D‘中。这样实际评估模型和期望评估模型都使用m个训练样本，而我们有数据总量1/3的，没有在训练集中出现的样本用于测试。这样的测试结果，亦称为”包外估计“。</p>
<p>&emsp;&emsp;自助法在数据集小，难以有效划分测试集/训练集时很有用。此外，自助法能从初始数据中产生多个不同的训练集，这对集成学习等方法有很大好处。然而自助法改变了初始数据集的分布，这会引入偏差。</p>
<p>&emsp;&emsp;因此在初始数据量足够但又不是特别大的时候，留出法和交叉验证法更常用一些。</p>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>&emsp;&emsp;基本术语：错误率，准确率（精度），训练误差，泛化误差，测试误差</p>
<p>&emsp;&emsp;经验误差与过拟合</p>
<p>&emsp;&emsp;评估方法：留出法，交叉验证法，自助法</p>
</div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习    </a><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理    </a><a class="post-meta__tags" href="/tags/%E7%AE%97%E6%B3%95/">算法    </a></div><div class="post_share"></div></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2020/08/20/%E5%88%86%E6%B2%BB%E6%B3%95%E5%88%B7%E9%A2%98%E6%80%BB%E7%BB%93/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/zhengguanyu/zhengguanyu.github.io@2.0/img/Second.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>分治法刷题总结</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/15/损失函数/" title="损失函数"><img class="relatedPosts_cover lazyload"data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/损失函数.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-15</div><div class="relatedPosts_title">损失函数</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/08/机器学习（1）/" title="机器学习（1）"><img class="relatedPosts_cover lazyload"data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/1.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-08</div><div class="relatedPosts_title">机器学习（1）</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/31/论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解/" title="论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片1.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-31</div><div class="relatedPosts_title">论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/11/【自我学习】胶囊网络CapsNet/" title="【自我学习】胶囊网络CapsNet"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200402110030173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1YW45NTAyMDU=,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-11</div><div class="relatedPosts_title">【自我学习】胶囊网络CapsNet</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/09/网站识别方案/" title="网站识别方案"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200809154715396.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzc3Nzg0MQ==,size_16,color_FFFFFF,t_70#pic_center"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-09</div><div class="relatedPosts_title">网站识别方案</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/13/西瓜书笔记：第3章·线性模型/" title="西瓜书笔记：第3章·线性模型"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200813024012574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDgwNzcxNA==,size_16,color_FFFFFF,t_70#pic_center"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-13</div><div class="relatedPosts_title">西瓜书笔记：第3章·线性模型</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By 东北石油大学智能技术与自然语言处理实验室</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">欢迎来到我们团队的博客！</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>