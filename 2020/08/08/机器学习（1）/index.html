<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>机器学习（1） | 东北石油大学智能技术与自然语言处理实验室</title><meta name="description" content="机器学习（1）"><meta name="keywords" content="算法,自然语言处理,机器学习"><meta name="author" content="东北石油大学智能技术与自然语言处理实验室"><meta name="copyright" content="东北石油大学智能技术与自然语言处理实验室"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/ava.jpg"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="机器学习（1）"><meta name="twitter:description" content="机器学习（1）"><meta name="twitter:image" content="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/1.jpg"><meta property="og:type" content="article"><meta property="og:title" content="机器学习（1）"><meta property="og:url" content="https://nlplab406.github.io/2020/08/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89/"><meta property="og:site_name" content="东北石油大学智能技术与自然语言处理实验室"><meta property="og:description" content="机器学习（1）"><meta property="og:image" content="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/1.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://nlplab406.github.io/2020/08/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89/"><link rel="prev" title="传统的机器学习方法——决策树（下）" href="https://nlplab406.github.io/2020/08/09/%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88%E4%B8%8B%EF%BC%89/"><link rel="next" title="论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》" href="https://nlplab406.github.io/2020/08/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E3%80%8AImproving%20Grammatical%20Error%20Correction%20via%20Pre-Training%20a%20Copy-Augmented%20Architecture%20with%20Unlabeled%20Data%E3%80%8B/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: true,
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">东北石油大学智能技术与自然语言处理实验室</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/ava.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">14</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">17</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">26</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#机器学习（1）"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">机器学习（1）</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#机器学习的基本原理："><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">机器学习的基本原理：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#机器学习的基本术语："><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">机器学习的基本术语：</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#假设空间与版本空间："><span class="toc_mobile_items-number">1.2.1.</span> <span class="toc_mobile_items-text">假设空间与版本空间：</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#那么我们来总结一下：在西瓜问题中，如何根据训练集求所对应的版本空间？"><span class="toc_mobile_items-number">1.2.1.1.</span> <span class="toc_mobile_items-text">那么我们来总结一下：在西瓜问题中，如何根据训练集求所对应的版本空间？</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#归纳偏好"><span class="toc_mobile_items-number">1.2.2.</span> <span class="toc_mobile_items-text">归纳偏好</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#没有免费的午餐定理（NFL）：任何算法在除训练集以外的样本空间预测误差的期望都是相同的"><span class="toc_mobile_items-number">1.2.2.1.</span> <span class="toc_mobile_items-text">没有免费的午餐定理（NFL）：任何算法在除训练集以外的样本空间预测误差的期望都是相同的</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#机器学习（1）"><span class="toc-number">1.</span> <span class="toc-text">机器学习（1）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#机器学习的基本原理："><span class="toc-number">1.1.</span> <span class="toc-text">机器学习的基本原理：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#机器学习的基本术语："><span class="toc-number">1.2.</span> <span class="toc-text">机器学习的基本术语：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#假设空间与版本空间："><span class="toc-number">1.2.1.</span> <span class="toc-text">假设空间与版本空间：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#那么我们来总结一下：在西瓜问题中，如何根据训练集求所对应的版本空间？"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">那么我们来总结一下：在西瓜问题中，如何根据训练集求所对应的版本空间？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#归纳偏好"><span class="toc-number">1.2.2.</span> <span class="toc-text">归纳偏好</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#没有免费的午餐定理（NFL）：任何算法在除训练集以外的样本空间预测误差的期望都是相同的"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">没有免费的午餐定理（NFL）：任何算法在除训练集以外的样本空间预测误差的期望都是相同的</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/1.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">机器学习（1）</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-08-08<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-08-08</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%A9%B9%E5%AD%90%E4%BE%9D/">詹子依</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E8%A9%B9%E5%AD%90%E4%BE%9D/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">3.9k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 12 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="机器学习（1）"><a href="#机器学习（1）" class="headerlink" title="机器学习（1）"></a>机器学习（1）</h1><p>&emsp;&emsp;<em>在学习一些复杂而有意思的知识之前呢，我想先来熟悉和理解机器学习的一些基本的概念和基本术语,它虽然没有什么大的作用，却也能让一些初学者和想了解机器学习的其他专业领域的人能更好的入门。“盖房子”吗，那就先从一砖一瓦开始。在看了周志华老师的“西瓜书”以及网上一些有趣的博客后，进而学习理解，总结了这篇笔记，如果有不够准确的地方，还请大家指出问题，一起学习一起讨论。</em></p>
<h2 id="机器学习的基本原理："><a href="#机器学习的基本原理：" class="headerlink" title="机器学习的基本原理："></a>机器学习的基本原理：</h2><blockquote>
<p>机器正是这样一门学科，它致力于研究如何<u>通过计算的手段，利用经验来改善系统自身的性能</u>。在计算机中，<u>”经验“经常以数据的形式存在</u>，因此机器学习所研究的主要内容，是关于<u>在计算机上从数据中产生”模型“的算法</u>，即<strong>学习算法</strong>。有了学习算法，我们把经验数据提供给它，他就能<u>基于这些数据</u>产生<strong>模型</strong>；在面对新情况时，模型会给我们提供相应的判断。</p>
</blockquote>
<p>&emsp;&emsp;我看到这样一个有趣的故事，能更简单通俗的解释机器学习：</p>
<blockquote>
<p>猫妈妈让猫娃娃抓老鼠。娃娃就问妈妈，老鼠长着什么样子？</p>
<p>猫妈妈说，老鼠长着胡须；于是它抓来一头大蒜。</p>
<p>猫妈妈说，老鼠长着四条腿；于是它抓来一个板凳。</p>
<p>猫妈妈说，老鼠长着一条尾巴；于是它抓来一个萝卜。</p>
</blockquote>
<p>&emsp;&emsp;这个故事里，猫娃娃就是一个基于规则的计算机程序，他完全听命于开发者猫妈妈的指令办事。但是因为三次指令不够全面，结果，三次都得出了错误的结果。</p>
<p>&emsp;&emsp;因此，猫妈妈应该怎么做呢？</p>
<p>&emsp;&emsp;她应该给娃娃看一些照片，并告诉娃娃，有些是老鼠，有些不是。比如：</p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/1.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:50%;" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/1.jpg" class="lazyload"></a></p>
<p>&emsp;&emsp;猫妈妈还要告诉娃娃：要<u>注意</u>老鼠的<u>耳朵；鼻子；尾巴</u>。</p>
<p>&emsp;&emsp;于是猫娃娃<u>通过对比</u>发现：老鼠的<u>耳朵</u>是圆的，别的动物要么没耳朵，要么不是圆形耳朵；老鼠都有<u>尾巴</u>，别的动物有的有，有的没有；老鼠的<u>鼻子</u>是尖的，别的动物不一定是这样。</p>
<p>&emsp;&emsp;于是猫娃娃就<u>用自己学到的</u>：“老鼠是<u>圆耳朵，有尾巴，尖鼻子</u>的动物”的信念去抓老鼠，那么猫娃娃就成了一个“<strong>老鼠分类器</strong>”</p>
<p>&emsp;&emsp;猫娃娃是<strong>机器</strong>，它<u>成为“老鼠分类器”的过程</u>，就叫做<strong>学习</strong>。</p>
<p>&emsp;&emsp;猫妈妈给的<u>那些照片</u>是用于学习的<strong>数据</strong>。</p>
<p>&emsp;&emsp;猫妈妈告知<u>要注意的几点</u>，是这个分类器的<strong>特征</strong>。</p>
<p>&emsp;&emsp;学习的结果（<u>老鼠分类器</u>）是一个<strong>模型</strong>。这个模型的类型可能是逻辑回归，或者朴素贝叶斯，或者决策树等等，总之是一个<u>分类模型</u>。</p>
<p>&emsp;&emsp;猫娃娃<u>思考的过程</u>就是<strong>算法</strong>。</p>
<p>&emsp;&emsp;通过这个有趣的小故事，是不是对机器学习的流程有一个简单的了解了呢？</p>
<p>&emsp;&emsp;下面是西瓜书一些基本术语的整理：</p>
<h2 id="机器学习的基本术语："><a href="#机器学习的基本术语：" class="headerlink" title="机器学习的基本术语："></a>机器学习的基本术语：</h2><p>&emsp;&emsp;<strong>数据集</strong>：例如：（色泽：乌黑，根蒂：稍蜷，敲声：沉闷），（色泽：浅白，根蒂：硬挺，敲声：清脆），……。这组记录的<u>集合</u>称为数据集。</p>
<p>&emsp;&emsp;<strong>样本/示例</strong>：上述数据集中的每条记录是<u>关于一个事件或对象的描述</u>。</p>
<p>&emsp;&emsp;<strong>属性</strong>：反应<u>事件或对象在某方面的特性或性质</u>的事项，例如：色泽、根蒂、敲声。</p>
<p>&emsp;&emsp;<strong>学习/训练</strong>：从数据中学得模型。</p>
<p>&emsp;&emsp;<strong>训练数据</strong>：训练过程中<u>用到的数据</u></p>
<p>&emsp;&emsp;<strong>训练样本</strong>：训练<u>用到的每个样本</u></p>
<p>&emsp;&emsp;<strong>训练集</strong>：训练样本<u>组成的集合</u></p>
<p>&emsp;&emsp;<strong>假设</strong>：<u>学得模型</u>对应了关于数据的某种潜在规律</p>
<p>&emsp;&emsp;<strong>真相</strong>：真正存在的潜在规律</p>
<p>&emsp;&emsp;<strong>学习器</strong>：<u>模型的另一种叫法</u>，把学习算法在给定数据和参数空间的实例化</p>
<p>&emsp;&emsp;<strong>预测</strong>：判断一个东西的属性</p>
<p>&emsp;&emsp;<strong>标记</strong>：关于<u>示例的结果信息</u>，比如我是一个“好人”。</p>
<p>&emsp;&emsp;<strong>样例</strong>：拥有标记的示例</p>
<p>&emsp;&emsp;<strong>标记空间/输出空间</strong>：所有标记的集合</p>
<p>&emsp;&emsp;<strong>分类</strong>：<u>预测时离散值</u>，比如把人分为好人和坏人之类的学习任务</p>
<p>&emsp;&emsp;<strong>回归</strong>：<u>预测值时连续值</u>，比如你的好人程度达到了0.9，0.6之类的</p>
<p>&emsp;&emsp;<strong>二分类</strong>：只涉及<u>两个类别</u>的分类任务</p>
<p>&emsp;&emsp;<strong>正类</strong>：二分类里的一个</p>
<p>&emsp;&emsp;<strong>反类</strong>：二分类里的另外一个</p>
<p>&emsp;&emsp;<strong>多分类</strong>：涉及多个类别的分类</p>
<p>&emsp;&emsp;<strong>测试</strong>：学习到模型之后<u>对样本进行预测</u>的过程</p>
<p>&emsp;&emsp;<strong>测试样本</strong>：被预测的样本</p>
<p>&emsp;&emsp;<strong>聚类</strong>：把<u>训练集中的对象</u>分为若干组</p>
<p>&emsp;&emsp;<strong>簇</strong>：<u>每一个组</u>叫簇</p>
<p>&emsp;&emsp;<strong>监督学习</strong>：训练数据<u>有标记信息</u>，例如，分类，回归。</p>
<p>&emsp;&emsp;<strong>无监督学习</strong>：训练数据<u>无标记信息</u>，例如，聚类。</p>
<blockquote>
<p>需要注意的是，机器学习的目标是使<u>学得的模型能很好的适用于“新样本”</u>，而不仅仅是在训练样本上工作的好；即便对于聚类这样的无监督学习任务，我们也希望学的的簇划分能适用于没在训练集中出现的样本。</p>
</blockquote>
<p>&emsp;&emsp;<strong>泛化能力</strong>：学得模型<u>适用于新样本的能力</u>。</p>
<p>&emsp;&emsp;<strong>独立同分布</strong>：通常假设样本空间中，全体样本服从一个未知“分布”，我们获得的<u>每个样本都是独立地从这个分布上采样获得的</u>。</p>
<h3 id="假设空间与版本空间："><a href="#假设空间与版本空间：" class="headerlink" title="假设空间与版本空间："></a>假设空间与版本空间：</h3><p>&emsp;&emsp;<strong>假设空间</strong>：属性所有可能取值组成的可能的样本</p>
<p>&emsp;&emsp;<strong>版本空间</strong>：与已知数据集一致的所有假设的子集集合。</p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/版本空间.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/版本空间.png" class="lazyload" title="1"></a></p>
<p>&emsp;&emsp;图中绿色加号代表正类样本，红色小圈代表负类样本。</p>
<p>&emsp;&emsp;GB是最大泛化正假设边界；SB是最大精确正假设边界。</p>
<p>&emsp;&emsp;GB与SB之间所围成的区域就是版本空间。</p>
<h4 id="那么我们来总结一下：在西瓜问题中，如何根据训练集求所对应的版本空间？"><a href="#那么我们来总结一下：在西瓜问题中，如何根据训练集求所对应的版本空间？" class="headerlink" title="那么我们来总结一下：在西瓜问题中，如何根据训练集求所对应的版本空间？"></a>那么我们来总结一下：在西瓜问题中，如何根据训练集求所对应的版本空间？</h4><p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/西瓜举例.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/西瓜举例.jpg" class="lazyload" title="2"></a></p>
<p>（1）写出假设空间：先列出<u>所有可能的样本点</u>（即每个属性都取到所有的属性值）</p>
<blockquote>
<p>即特征向量：例如，我们把“色泽”，“根蒂”，“敲声”作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位置。由于<u>空间中的每个点对应一个坐标向量</u>，因此我们也把<u>一个示例称为一个“特征向量”</u></p>
</blockquote>
<p>（2）<u>对应</u>着给出的<u>已知数据集</u>，将<u>与正样本不一致的、与负样本一致的假设删除</u>。</p>
<p>&emsp;&emsp;即可得出<u>与训练集一致的假设集合</u>（即能<u>对所有训练样本</u>进行正确的判断），也就是<strong>版本空间</strong>了。</p>
<p>表1.1的训练数据集对应的假设空间应该如下：（色泽，根蒂，敲声分别有2，3，3种可能取值。则假设空间规模大小：3x4x4+1=49）</p>
<p>表1.1的训练数据集对应的假设空间应该如下：</p>
<p><del>1 色泽＝＊，根蒂＝＊，敲声＝＊</del>                                 </p>
<p><del>2 色泽＝青绿，根蒂＝＊，敲声＝＊</del></p>
<p><del>3 色泽＝乌黑，根蒂＝＊，敲声＝＊</del></p>
<p><strong>4 色泽＝＊，根蒂＝蜷缩，敲声＝＊</strong></p>
<p><del>5 色泽＝＊，根蒂＝硬挺，敲声＝＊</del></p>
<p><del>6 色泽＝＊，根蒂＝稍蜷，敲声＝＊</del></p>
<p><strong>7 色泽＝＊，根蒂＝＊，敲声＝浊响</strong></p>
<p><del>8 色泽＝＊，根蒂＝＊，敲声＝清脆</del></p>
<p><del>9 色泽＝＊，根蒂＝＊，敲声＝沉闷</del></p>
<p><del>10 色泽＝青绿，根蒂＝蜷缩，敲声＝＊</del></p>
<p><del>11 色泽＝青绿，根蒂＝硬挺，敲声＝＊</del></p>
<p><del>12 色泽＝青绿，根蒂＝稍蜷，敲声＝＊</del></p>
<p><del>13 色泽＝乌黑，根蒂＝蜷缩，敲声＝＊</del></p>
<p><del>14 色泽＝乌黑，根蒂＝硬挺，敲声＝＊</del></p>
<p><del>15 色泽＝乌黑，根蒂＝稍蜷，敲声＝＊</del></p>
<p><del>16 色泽＝青绿，根蒂＝＊，敲声＝浊响</del></p>
<p><del>17 色泽＝青绿，根蒂＝＊，敲声＝清脆</del></p>
<p><del>18 色泽＝青绿，根蒂＝＊，敲声＝沉闷</del></p>
<p><del>19 色泽＝乌黑，根蒂＝＊，敲声＝浊响</del></p>
<p><del>20 色泽＝乌黑，根蒂＝＊，敲声＝清脆</del></p>
<p><del>21 色泽＝乌黑，根蒂＝＊，敲声＝沉闷</del></p>
<p><strong>22 色泽＝＊，根蒂＝蜷缩，敲声＝浊响</strong></p>
<p><del>23 色泽＝＊，根蒂＝蜷缩，敲声＝清脆</del></p>
<p><del>24 色泽＝＊，根蒂＝蜷缩，敲声＝沉闷</del></p>
<p><del>25 色泽＝＊，根蒂＝硬挺，敲声＝浊响</del></p>
<p><del>26 色泽＝＊，根蒂＝硬挺，敲声＝清脆</del></p>
<p><del>27 色泽＝＊，根蒂＝硬挺，敲声＝沉闷</del></p>
<p><del>28 色泽＝＊，根蒂＝稍蜷，敲声＝浊响</del></p>
<p><del>29 色泽＝＊，根蒂＝稍蜷，敲声＝清脆</del></p>
<p><del>30 色泽＝＊，根蒂＝稍蜷，敲声＝沉闷</del></p>
<p><del>31 色泽＝青绿，根蒂＝蜷缩，敲声＝浊响</del></p>
<p><del>32 色泽＝青绿，根蒂＝蜷缩，敲声＝清脆</del></p>
<p><del>33 色泽＝青绿，根蒂＝蜷缩，敲声＝沉闷</del></p>
<p><del>34 色泽＝青绿，根蒂＝硬挺，敲声＝浊响</del></p>
<p><del>35 色泽＝青绿，根蒂＝硬挺，敲声＝清脆</del></p>
<p><del>36 色泽＝青绿，根蒂＝硬挺，敲声＝沉闷</del></p>
<p><del>37 色泽＝青绿，根蒂＝稍蜷，敲声＝浊响</del></p>
<p><del>38 色泽＝青绿，根蒂＝稍蜷，敲声＝清脆</del></p>
<p><del>39 色泽＝青绿，根蒂＝稍蜷，敲声＝沉闷</del></p>
<p><del>40 色泽＝乌黑，根蒂＝蜷缩，敲声＝浊响</del></p>
<p><del>41 色泽＝乌黑，根蒂＝蜷缩，敲声＝清脆</del></p>
<p><del>42 色泽＝乌黑，根蒂＝蜷缩，敲声＝沉闷</del></p>
<p><del>43 色泽＝乌黑，根蒂＝硬挺，敲声＝浊响</del></p>
<p><del>44 色泽＝乌黑，根蒂＝硬挺，敲声＝清脆</del></p>
<p><del>45 色泽＝乌黑，根蒂＝硬挺，敲声＝沉闷</del></p>
<p><del>46 色泽＝乌黑，根蒂＝稍蜷，敲声＝浊响</del></p>
<p><del>47 色泽＝乌黑，根蒂＝稍蜷，敲声＝清脆</del></p>
<p><del>48 色泽＝乌黑，根蒂＝稍蜷，敲声＝沉闷</del></p>
<p><del>49 Ø</del></p>
<p>根据总结，按照上述过程进行学习：</p>
<p>（1）（色泽＝青绿、根蒂＝蜷缩、敲声＝浊响），好瓜</p>
<p>可以删除假设空间中的3、5、6、8、9、11-15、17-21、23-30、32-49</p>
<p>（2）（色泽＝乌黑、根蒂＝蜷缩、敲声＝浊响），好瓜</p>
<p>可以删除剩余假设空间中的2、10、16、31</p>
<p>（3）（色泽＝青绿、根蒂＝硬挺、敲声＝清脆），坏瓜</p>
<p>可以删除剩余假设空间中的1</p>
<p>（4）（色泽＝乌黑、根蒂＝稍蜷、敲声＝沉闷），坏瓜</p>
<p>剩余假设空间中无可删除的假设</p>
<p>&emsp;&emsp;学习过后剩余的假设为：</p>
<p>4 色泽＝＊，根蒂＝蜷缩，敲声＝＊</p>
<p>7 色泽＝＊，根蒂＝＊，敲声＝浊响</p>
<p>22 色泽＝＊，根蒂＝蜷缩，敲声＝浊响</p>
<p>&emsp;&emsp;这就是最后的“假设集合”，也就是“<strong>版本空间</strong>”</p>
<h3 id="归纳偏好"><a href="#归纳偏好" class="headerlink" title="归纳偏好"></a>归纳偏好</h3><blockquote>
<p>任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。可以想象，<u>如果没有偏好，我们的西瓜学习算法产生的模型每次在进行预测时随机抽选训练集上的等效假设，那么这个新瓜“（色泽=青绿；根蒂=蜷缩；敲声=沉闷）”，学得模型时而告诉我们它是好的，时而告诉我们它是不好的，</u>这样的学习结果显然没有意义。</p>
</blockquote>
<p><br></p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/归纳偏好.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/归纳偏好.jpg" class="lazyload" title="3"></a></p>
<p><br></p>
<blockquote>
<p>归纳偏好的作用在图1.3这个回归学习图示中可能更直观。这里的每个训练样本是图中的一个点（x，y）<u>，要学得一个与训练集一致的模型，相当于找到一条穿过图中所有训练样本点的曲线</u>。显然，<u>对有限个样本点组成的训练集，存在很多条曲线与其一致</u>。我们的学习算法必须有某种偏好，才能产出它认为“正确”的模型。<br><u>那么有没有一般性的原则来引导算法确立“正确的”偏好呢？</u><br><u>“奥卡姆剃刀”</u>是一种常用的，自然科学研究中最基本的原则，即“<u>若有多个假设与观察一致，则选最简单的那个</u>”<br>如果采用这个原则，并假设我们认为“更平滑”意味着“更简单”，例如曲线A更容易描述。则在图中，我们会自然地偏好“平滑”的曲线A。</p>
<p><u>然而，奥卡姆剃刀并非唯一可行的原则</u>。</p>
<p>归纳偏好对应了学习算法本身所做出的关于“什么样模型更好”的假设。<u>在具体现实问题中，这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法是否能取得好的性能</u>。</p>
</blockquote>
<h4 id="没有免费的午餐定理（NFL）：任何算法在除训练集以外的样本空间预测误差的期望都是相同的"><a href="#没有免费的午餐定理（NFL）：任何算法在除训练集以外的样本空间预测误差的期望都是相同的" class="headerlink" title="没有免费的午餐定理（NFL）：任何算法在除训练集以外的样本空间预测误差的期望都是相同的"></a>没有免费的午餐定理（NFL）：任何算法在除训练集以外的样本空间预测误差的期望都是相同的</h4><p>&emsp;&emsp;让我们再回头看看图1.3.假设学习算法a基于某种归纳偏好产生了对应于曲线A的模型，学习算法B基于另一种归纳偏好产生了对应于曲线B模型。</p>
<p><br></p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/NFL.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="4" class="fancybox"><img alt="4" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/NFL.jpg" class="lazyload" title="4"></a></p>
<p><br></p>
<blockquote>
<p>基于前面讨论的平滑曲线的某种描述简单性。我们满怀信心的期待算法la比lb更好，确实图1.4（a）显示出与B相比，A与训练集外的样本更一致，换言之，A的泛化能力比B强。</p>
<p>但是对于一个学习算法la，若它在某些问题上比学习算法lb好，则必然存在另一些问题，在那里b比a好。</p>
</blockquote>
<p>&emsp;&emsp;这里说的表现好就是前面所说的泛化能力更强。然后出现了下面这个公式:</p>
<p><br></p>
<script type="math/tex; mode=display">
Eote(la|X,f)=\sum h\sum x \in \chi-X P(x)I(h(x)\ne f(x))P（h|X,la)</script><p><br></p>
<p><a href="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/NPL2.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="6" class="fancybox"><img alt="6" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/NPL2.jpg" class="lazyload" title="6"></a></p>
<p><br></p>
<p>&emsp;&emsp;经过推导，可以看出，总误差与学习算法无关。那么对于两个学习算法la和lb我们都有：</p>
<p><br></p>
<script type="math/tex; mode=display">
\sum fEote(la|X,f)=\sum f Eote(lb|X,f)</script><p><br></p>
<p>&emsp;&emsp;无论学习算法la多聪明，算法lb多笨拙，他们的期望性能竟然相同。这就是NFL定理。</p>
<blockquote>
<p>我们需要注意到，<u>NFL定理有一个重要前提，所有问题出现的机会相同或所有问题同等重要</u>，<u>但实际情形并不是这样</u>，很多时候我们只关注自己正在试图解决的问题，希望他找到一个解决方案，至于这个问题解决方案在别的问题甚至相似的问题上，是否为好方案，我们并不关心。事实上上面的NFL定理的简短论述过程中，<u>假设f的均匀分布</u>，而实际情况并非如此。所以<u>NFL定理最重要的寓意是让我们清楚的认识到，脱离具体问题，空谈什么学习方法更好毫无意义</u>，因为若考虑所有潜在的问题，则所有学习算法都一样好，要谈论算法的相对优劣，<u>必须针对具体的学习问题，在某些问题上表现好。在另一些问题上却可能不尽如人意</u>。学习算法自身的<u>归纳偏好与问题是否相配</u>，往往会起到决定性的作用</p>
</blockquote>
<p>&emsp;&emsp;以上就是我的机器学习（1）笔记的内容，主要了解了机器学习的基本概念和一些基本术语，并对其中几个重要的术语有了详细的解释和推算。我知道还存在很多不足，请大家多多指教，谢谢大家！</p>
</div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%AE%97%E6%B3%95/">算法    </a><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理    </a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习    </a></div><div class="post_share"></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/08/09/%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88%E4%B8%8B%EF%BC%89/"><img class="prev_cover lazyload" data-src="https://img-blog.csdnimg.cn/20200809164842535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>传统的机器学习方法——决策树（下）</span></div></a></div><div class="next-post pull_right"><a href="/2020/08/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E3%80%8AImproving%20Grammatical%20Error%20Correction%20via%20Pre-Training%20a%20Copy-Augmented%20Architecture%20with%20Unlabeled%20Data%E3%80%8B/"><img class="next_cover lazyload" data-src="https://img-blog.csdnimg.cn/20200803210957976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/07/31/论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解/" title="论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片1.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-31</div><div class="relatedPosts_title">论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/传统的机器学习方法——决策树（上）/" title="传统的机器学习方法——决策树（上）"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200802172055879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">传统的机器学习方法——决策树（上）</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/命名实体识别简介（一）/" title="命名实体识别简介（一）"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200802093111103.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hhcHB5ZXZlcnl5ZGF5,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">命名实体识别简介（一）</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/知识图谱/" title="知识图谱"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.4/img/张明磊/8.2/图片2.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">知识图谱</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/09/网站识别方案/" title="网站识别方案"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200809154715396.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzc3Nzg0MQ==,size_16,color_FFFFFF,t_70#pic_center"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-09</div><div class="relatedPosts_title">网站识别方案</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/09/传统的机器学习方法——决策树（下）/" title="传统的机器学习方法——决策树（下）"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200809164842535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-09</div><div class="relatedPosts_title">传统的机器学习方法——决策树（下）</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By 东北石油大学智能技术与自然语言处理实验室</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">欢迎来到我们团队的博客！</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>