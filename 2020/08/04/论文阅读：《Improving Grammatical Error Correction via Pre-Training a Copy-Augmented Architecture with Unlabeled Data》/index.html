<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》 | 东北石油大学智能技术与自然语言处理实验室</title><meta name="description" content="论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》"><meta name="keywords" content="NLP,深度学习"><meta name="author" content="东北石油大学智能技术与自然语言处理实验室"><meta name="copyright" content="东北石油大学智能技术与自然语言处理实验室"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/ava.jpg"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》"><meta name="twitter:description" content="论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》"><meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200803210957976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70"><meta property="og:type" content="article"><meta property="og:title" content="论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》"><meta property="og:url" content="https://nlplab406.github.io/2020/08/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E3%80%8AImproving%20Grammatical%20Error%20Correction%20via%20Pre-Training%20a%20Copy-Augmented%20Architecture%20with%20Unlabeled%20Data%E3%80%8B/"><meta property="og:site_name" content="东北石油大学智能技术与自然语言处理实验室"><meta property="og:description" content="论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》"><meta property="og:image" content="https://img-blog.csdnimg.cn/20200803210957976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://nlplab406.github.io/2020/08/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9A%E3%80%8AImproving%20Grammatical%20Error%20Correction%20via%20Pre-Training%20a%20Copy-Augmented%20Architecture%20with%20Unlabeled%20Data%E3%80%8B/"><link rel="prev" title="机器学习（1）" href="https://nlplab406.github.io/2020/08/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89/"><link rel="next" title="分类任务评价指标" href="https://nlplab406.github.io/2020/08/02/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: true,
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">东北石油大学智能技术与自然语言处理实验室</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/ava.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">30</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">32</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">31</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Pointer-Networks"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">Pointer Networks</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#传统seq2seq模型的decoder做预测"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">传统seq2seq模型的decoder做预测</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#普通seq2seq模型与Pointer-network的对比"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">普通seq2seq模型与Pointer network的对比</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#带有pointer-network的seq2seq模型"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">带有pointer network的seq2seq模型</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#论文笔记"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">论文笔记</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#引言"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">引言</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#总体模型图"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">总体模型图</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#预训练"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">预训练</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#降噪自编码"><span class="toc_mobile_items-number">2.3.1.</span> <span class="toc_mobile_items-text">降噪自编码</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#预训练decoder"><span class="toc_mobile_items-number">2.3.2.</span> <span class="toc_mobile_items-text">预训练decoder</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#多任务学习"><span class="toc_mobile_items-number">2.4.</span> <span class="toc_mobile_items-text">多任务学习</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#token级别的标注任务"><span class="toc_mobile_items-number">2.4.1.</span> <span class="toc_mobile_items-text">token级别的标注任务</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#句子级别的拷贝任务"><span class="toc_mobile_items-number">2.4.2.</span> <span class="toc_mobile_items-text">句子级别的拷贝任务</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#实验结果"><span class="toc_mobile_items-number">2.5.</span> <span class="toc_mobile_items-text">实验结果</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#注意力可视化"><span class="toc_mobile_items-number">2.6.</span> <span class="toc_mobile_items-text">注意力可视化</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Pointer-Networks"><span class="toc-number">1.</span> <span class="toc-text">Pointer Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#传统seq2seq模型的decoder做预测"><span class="toc-number">1.1.</span> <span class="toc-text">传统seq2seq模型的decoder做预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#普通seq2seq模型与Pointer-network的对比"><span class="toc-number">1.2.</span> <span class="toc-text">普通seq2seq模型与Pointer network的对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#带有pointer-network的seq2seq模型"><span class="toc-number">1.3.</span> <span class="toc-text">带有pointer network的seq2seq模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#论文笔记"><span class="toc-number">2.</span> <span class="toc-text">论文笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#引言"><span class="toc-number">2.1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总体模型图"><span class="toc-number">2.2.</span> <span class="toc-text">总体模型图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#预训练"><span class="toc-number">2.3.</span> <span class="toc-text">预训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#降噪自编码"><span class="toc-number">2.3.1.</span> <span class="toc-text">降噪自编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#预训练decoder"><span class="toc-number">2.3.2.</span> <span class="toc-text">预训练decoder</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多任务学习"><span class="toc-number">2.4.</span> <span class="toc-text">多任务学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#token级别的标注任务"><span class="toc-number">2.4.1.</span> <span class="toc-text">token级别的标注任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#句子级别的拷贝任务"><span class="toc-number">2.4.2.</span> <span class="toc-text">句子级别的拷贝任务</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实验结果"><span class="toc-number">2.5.</span> <span class="toc-text">实验结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#注意力可视化"><span class="toc-number">2.6.</span> <span class="toc-text">注意力可视化</span></a></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://img-blog.csdnimg.cn/20200803210957976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70)"><div id="post-info"><div id="post-title"><div class="posttitle">论文阅读：《Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data》</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-08-04<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-08-04</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%AE%97%E6%9D%A8/">宗杨</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%AE%97%E6%9D%A8/NLP/">NLP</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">1.3k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 4 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="Pointer-Networks"><a href="#Pointer-Networks" class="headerlink" title="Pointer Networks"></a>Pointer Networks</h1><p>&emsp;&emsp;本文提出使用copy机制用在文本纠错的训练中，从本文中引用的论文可以了解到本文的copy机制就是借鉴了Pointer network。</p>
<h2 id="传统seq2seq模型的decoder做预测"><a href="#传统seq2seq模型的decoder做预测" class="headerlink" title="传统seq2seq模型的decoder做预测"></a>传统seq2seq模型的decoder做预测</h2><p><a href="https://img-blog.csdnimg.cn/20200803210957976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200803210957976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" class="lazyload" title="在这里插入图片描述"></a></p>
<p>&emsp;&emsp;传统seq2seq模型的decoder在做预测时，经过最后一个softmax层得到一个词表长度大小的向量，值最大对应位置的单词即为当前的输出。图中的例子是词的个数仅为5的词表</p>
<h2 id="普通seq2seq模型与Pointer-network的对比"><a href="#普通seq2seq模型与Pointer-network的对比" class="headerlink" title="普通seq2seq模型与Pointer network的对比"></a>普通seq2seq模型与Pointer network的对比</h2><p><a href="https://img-blog.csdnimg.cn/20200803210618231.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200803210618231.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" class="lazyload" title="在这里插入图片描述"></a></p>
<p>&emsp;&emsp;传统seq2seq模型的公式：<br>$\begin{aligned} u_{j}^{i} &amp;=v^{T} \tanh \left(W_{1} e_{j}+W_{2} d_{i}\right) \quad j \in(1, \ldots, n) \\ a_{j}^{i} &amp;=\operatorname{softmax}\left(u_{j}^{i}\right) \quad j \in(1, \ldots, n) \\ d_{i}^{\prime} &amp;=\sum_{j=1}^{n} a_{j}^{i} e_{j} \end{aligned}$</p>
<p><a href="https://img-blog.csdnimg.cn/20200803210408992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200803210408992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" class="lazyload" title="在这里插入图片描述"></a></p>
<p>&emsp;&emsp;pointer network的公式：</p>
<p>$\begin{aligned} u_{j}^{i} &amp;=v^{T} \tanh \left(W_{1} e_{j}+W_{2} d_{i}\right) \quad j \in(1, \ldots, n) \\ p\left(C_{i} \mid C_{1}, \ldots, C_{i-1}, \mathcal{P}\right) &amp;=\operatorname{softmax}\left(u^{i}\right) \end{aligned}$</p>
<p>&emsp;&emsp;从图a可以看出常规seq2seq模型的过程：首先encoder部分对输入序列进行编码，然后对编码后的向量做attention，最后decoder部分对attention后的向量进行解码从而得到预测结果。从图b中可以看到Pointer Networks的不同点：得到预测结果的方式便是输出一个概率分布，也即所谓的指针（pointer）。传统带有注意力机制的seq2seq模型输出的是针对输出词汇表的一个概率分布，而Pointer Networks输出的则是针对输入文本序列的概率分布。</p>
<h2 id="带有pointer-network的seq2seq模型"><a href="#带有pointer-network的seq2seq模型" class="headerlink" title="带有pointer network的seq2seq模型"></a>带有pointer network的seq2seq模型</h2><p><a href="https://img-blog.csdnimg.cn/20200803211932181.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200803211932181.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" class="lazyload" title="在这里插入图片描述"></a></p>
<p>&emsp;&emsp;在每一次预测的时候，通过传统seq2seq模型的预测（即softmax层的结果）可以得到针对词汇表的概率分布（图中绿色柱形图），然后通过Pointer Networks可以得到针对输入序列的概率分布（图中蓝色柱形图），对二者做并集就可以得到结合了输入文本中词汇和预测词汇表的一个概率分布，这样一来模型就有可能直接从输入文本中复制一些词到输出结果中。</p>
<h1 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p><a href="https://img-blog.csdnimg.cn/20200803212139117.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200803212139117.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" class="lazyload" title="在这里插入图片描述"></a></p>
<p>&emsp;&emsp;语法错误纠正（GEC）任务是检测并纠正文本中的语法错误。机器翻译系统在GEC中取得了不错的效果，但是GEC不同于翻译的地方在于GEC只是改动句子中的几个词语，表1统计了不同语料集中，原始句子和目标句子相同的比例。可以看到80%以上的词语是可以直接从原始句子中拷贝过去的。</p>
<h2 id="总体模型图"><a href="#总体模型图" class="headerlink" title="总体模型图"></a>总体模型图</h2><p><a href="https://img-blog.csdnimg.cn/20200803212235544.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200803212235544.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" class="lazyload" title="在这里插入图片描述"></a></p>
<p>&emsp;&emsp;公式：</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.7/img/宗杨/8.4/图片.jpg" target="_blank" rel="noopener" data-fancybox="group" data-caption="公式" class="fancybox"><img alt="公式" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.7/img/宗杨/8.4/图片.jpg" class="lazyload" title="公式"></a></p>
<script type="math/tex; mode=display">
\begin{aligned} A_{t}=q_{t}^{T} K & \\ P_{t}^{c o p y}(w)=\operatorname{softmax}\left(A_{t}\right) & \\ \alpha_{t}^{c o p y}=\operatorname{sigmoid}\left(W^{T} \sum_{t}\left(A_{t}^{T} \cdot V\right)\right) \end{aligned}</script><h2 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h2><h3 id="降噪自编码"><a href="#降噪自编码" class="headerlink" title="降噪自编码"></a>降噪自编码</h3><p>&emsp;&emsp;降噪自编码常用于模型初始化时从输入中提取和选择特征，BERT使用双向transformer模型，在多数NLP任务中的表现都超过了现有系统。BERT在处理的过程中选取了15%的词语，在这15%的词语中：80%的词语使用MASK代替，10%采用随机词语，剩下的10%保持原有词语。<br>&emsp;&emsp;作者借鉴了BERT和降噪自编码思想，作者对于未标记的语料对做了如下处理：</p>
<ul>
<li>10%的概率删除一个词语。</li>
<li>10%的概率增加一个词语。</li>
<li>10%的概率随机替换一个词语。</li>
<li>按照一个正态分布的偏差打散词语。</li>
</ul>
<p>&emsp;&emsp;用处理后的数据对带有copy机制的seq2seq模型进行预训练</p>
<h3 id="预训练decoder"><a href="#预训练decoder" class="headerlink" title="预训练decoder"></a>预训练decoder</h3><p>在NLP任务中，预训练部分模型也同样能够提升效果。作者初始化拷贝机制的decoer通过预训练参数形式，其他参数进行随机初始化。</p>
<h2 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h2><h3 id="token级别的标注任务"><a href="#token级别的标注任务" class="headerlink" title="token级别的标注任务"></a>token级别的标注任务</h3><p>&emsp;&emsp;作者为源句子增加了token级别的标注任务，具体说来就是标识原始句子中的每个词语是否正确。<br>&emsp;&emsp;对于原始句子中的每个词语xi，对应于目标句子中的一个词语yj，如果xi=yj，则将其标注为正确，否则则为错误。预测的时候是通过将encoder最终状态送入softmax。</p>
<h3 id="句子级别的拷贝任务"><a href="#句子级别的拷贝任务" class="headerlink" title="句子级别的拷贝任务"></a>句子级别的拷贝任务</h3><p>&emsp;&emsp;这个任务的主要目的是当句子看似整体正确时，模型能够做尽可能多的拷贝。训练过程中将相等数量的正确句子和修改的句子对输入到模型中，当输入的是正确句子时，移除decoder层的atttntion处理。没有了encoder-decoder注意力，生成模型很难工作，因此模型的拷贝部分的能力将会提升。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><a href="https://img-blog.csdnimg.cn/2020080321281331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/2020080321281331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" class="lazyload" title="在这里插入图片描述"></a></p>
<p><a href="https://img-blog.csdnimg.cn/20200803212820451.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200803212820451.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" class="lazyload" title="在这里插入图片描述"></a></p>
<h2 id="注意力可视化"><a href="#注意力可视化" class="headerlink" title="注意力可视化"></a>注意力可视化</h2><p><a href="https://img-blog.csdnimg.cn/20200803212857738.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption="在这里插入图片描述" class="fancybox"><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20200803212857738.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3oxMTAzNzU3MDQ3,size_16,color_FFFFFF,t_70" class="lazyload" title="在这里插入图片描述"></a></p>
<p>&emsp;&emsp;拷贝注意力权重集中在下一个词，而生成模型的注意力更集中在其他词比如附近的词或者句尾词。生成部分寻找长依赖并且更关注全局信息。</p>
</div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NLP/">NLP    </a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习    </a></div><div class="post_share"></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/08/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89/"><img class="prev_cover lazyload" data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/1.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>机器学习（1）</span></div></a></div><div class="next-post pull_right"><a href="/2020/08/02/%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/zhengguanyu/PhotoRepos@v1.1/img/封面.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>分类任务评价指标</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/24/git pycharm 你会遇到的坑 我帮你填/" title="git pycharm 你会遇到的坑 我帮你填"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.9/img/闫凯峰/8.24/图片 1.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-24</div><div class="relatedPosts_title">git pycharm 你会遇到的坑 我帮你填</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/01/【论文阅读笔记PCNN】Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks/" title="【论文阅读笔记PCNN】Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200801134611553.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-01</div><div class="relatedPosts_title">【论文阅读笔记PCNN】Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/10/【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training/" title="【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/2020071920490854.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-10</div><div class="relatedPosts_title">【论文阅读笔记】Span-based Joint Entity and Relation Extraction with Transformer Pre-training</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/分类任务评价指标/" title="分类任务评价指标"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/zhengguanyu/PhotoRepos@v1.1/img/封面.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">分类任务评价指标</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/24/置信学习清洗脏数据/" title="置信学习清洗脏数据"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.10/img/闫凯峰/8.25/3连.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-24</div><div class="relatedPosts_title">置信学习清洗脏数据</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/09/传统的机器学习方法——决策树（下）/" title="传统的机器学习方法——决策树（下）"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200809164842535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-09</div><div class="relatedPosts_title">传统的机器学习方法——决策树（下）</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By 东北石油大学智能技术与自然语言处理实验室</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">欢迎来到我们团队的博客！</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>