<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解 | 东北石油大学智能技术与自然语言处理实验室</title><meta name="description" content="论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解"><meta name="keywords" content="机器学习,卷积神经网络,自然语言处理,深度学习,算法"><meta name="author" content="东北石油大学智能技术与自然语言处理实验室"><meta name="copyright" content="东北石油大学智能技术与自然语言处理实验室"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/ava.jpg"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解"><meta name="twitter:description" content="论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片1.png"><meta property="og:type" content="article"><meta property="og:title" content="论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解"><meta property="og:url" content="https://nlplab406.github.io/2020/07/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AWhat%20Do%20We%20Understand%20About%20Convolutional%20Networks%EF%BC%9F%20%E5%AF%B9%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BA%86%E8%A7%A3/"><meta property="og:site_name" content="东北石油大学智能技术与自然语言处理实验室"><meta property="og:description" content="论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片1.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://nlplab406.github.io/2020/07/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AWhat%20Do%20We%20Understand%20About%20Convolutional%20Networks%EF%BC%9F%20%E5%AF%B9%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BA%86%E8%A7%A3/"><link rel="prev" title="手把手教你初始化Vue项目并部署在github上" href="https://nlplab406.github.io/2020/08/01/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%88%9D%E5%A7%8B%E5%8C%96Vue%E9%A1%B9%E7%9B%AE%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%9C%A8github%E4%B8%8A/"><link rel="next" title="读写excel" href="https://nlplab406.github.io/2020/07/30/%E8%AF%BB%E5%86%99excel/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: true,
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">东北石油大学智能技术与自然语言处理实验室</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/ava.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">27</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">30</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">31</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#What-Do-We-Understand-About-Convolutional-Networks"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">What Do We Understand About Convolutional Networks?</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#目录"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">目录</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-引言"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">1 引言</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-1-动机"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">1.1 动机</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-2-目标"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">1.2 目标</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-3-报告提纲"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">1.3 报告提纲</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#2-多层网络"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">2 多层网络</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-1-多层架构"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">2.1 多层架构</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-1-1-神经网络"><span class="toc_mobile_items-number">3.1.1.</span> <span class="toc_mobile_items-text">2.1.1 神经网络</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-1-2-循环神经网络"><span class="toc_mobile_items-number">3.1.2.</span> <span class="toc_mobile_items-text">2.1.2 循环神经网络</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-1-3-卷积网络"><span class="toc_mobile_items-number">3.1.3.</span> <span class="toc_mobile_items-text">2.1.3 卷积网络</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-1-4-生成对抗网络"><span class="toc_mobile_items-number">3.1.4.</span> <span class="toc_mobile_items-text">2.1.4 生成对抗网络</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-1-5-多层网络的训练"><span class="toc_mobile_items-number">3.1.5.</span> <span class="toc_mobile_items-text">2.1.5 多层网络的训练</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-1-6-简单说说迁移学习"><span class="toc_mobile_items-number">3.1.6.</span> <span class="toc_mobile_items-text">2.1.6 简单说说迁移学习</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-2-空间卷积网络"><span class="toc_mobile_items-number">3.2.</span> <span class="toc_mobile_items-text">2.2 空间卷积网络</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-2-1-CNN-近期发展中的关键架构"><span class="toc_mobile_items-number">3.2.1.</span> <span class="toc_mobile_items-text">2.2.1 CNN 近期发展中的关键架构</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-2-2-实现-CNN-的不变性"><span class="toc_mobile_items-number">3.2.2.</span> <span class="toc_mobile_items-text">2.2.2 实现 CNN 的不变性</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-2-3-实现-CNN-的定位"><span class="toc_mobile_items-number">3.2.3.</span> <span class="toc_mobile_items-text">2.2.3 实现 CNN 的定位</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-3-时空卷积网络"><span class="toc_mobile_items-number">3.3.</span> <span class="toc_mobile_items-text">2.3 时空卷积网络</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-3-1-基于-LSTM-的时空-CNN"><span class="toc_mobile_items-number">3.3.1.</span> <span class="toc_mobile_items-text">2.3.1 基于 LSTM 的时空 CNN</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-3-2-3D-CNN"><span class="toc_mobile_items-number">3.3.2.</span> <span class="toc_mobile_items-text">2.3.2 3D CNN</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-3-3-Two-Stream-CNN"><span class="toc_mobile_items-number">3.3.3.</span> <span class="toc_mobile_items-text">2.3.3 Two-Stream CNN</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-4-总体讨论"><span class="toc_mobile_items-number">3.4.</span> <span class="toc_mobile_items-text">2.4 总体讨论</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#3-理解-CNN-的构建模块"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">3 理解 CNN 的构建模块</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-1-卷积层"><span class="toc_mobile_items-number">4.1.</span> <span class="toc_mobile_items-text">3.1 卷积层</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-2-整流"><span class="toc_mobile_items-number">4.2.</span> <span class="toc_mobile_items-text">3.2 整流</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-3-归一化"><span class="toc_mobile_items-number">4.3.</span> <span class="toc_mobile_items-text">3.3 归一化</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-4-池化"><span class="toc_mobile_items-number">4.4.</span> <span class="toc_mobile_items-text">3.4 池化</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-5-总体讨论"><span class="toc_mobile_items-number">4.5.</span> <span class="toc_mobile_items-text">3.5 总体讨论</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#4-当前状态"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">4 当前状态</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-1-当前趋势"><span class="toc_mobile_items-number">5.1.</span> <span class="toc_mobile_items-text">4.1 当前趋势</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-2-仍待解决的问题"><span class="toc_mobile_items-number">5.2.</span> <span class="toc_mobile_items-text">4.2 仍待解决的问题</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-Do-We-Understand-About-Convolutional-Networks"><span class="toc-number">1.</span> <span class="toc-text">What Do We Understand About Convolutional Networks?</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#目录"><span class="toc-number">1.1.</span> <span class="toc-text">目录</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-引言"><span class="toc-number">2.</span> <span class="toc-text">1 引言</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-动机"><span class="toc-number">2.1.</span> <span class="toc-text">1.1 动机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-目标"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-报告提纲"><span class="toc-number">2.3.</span> <span class="toc-text">1.3 报告提纲</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-多层网络"><span class="toc-number">3.</span> <span class="toc-text">2 多层网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-多层架构"><span class="toc-number">3.1.</span> <span class="toc-text">2.1 多层架构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-神经网络"><span class="toc-number">3.1.1.</span> <span class="toc-text">2.1.1 神经网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-循环神经网络"><span class="toc-number">3.1.2.</span> <span class="toc-text">2.1.2 循环神经网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-3-卷积网络"><span class="toc-number">3.1.3.</span> <span class="toc-text">2.1.3 卷积网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-4-生成对抗网络"><span class="toc-number">3.1.4.</span> <span class="toc-text">2.1.4 生成对抗网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-5-多层网络的训练"><span class="toc-number">3.1.5.</span> <span class="toc-text">2.1.5 多层网络的训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-6-简单说说迁移学习"><span class="toc-number">3.1.6.</span> <span class="toc-text">2.1.6 简单说说迁移学习</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-空间卷积网络"><span class="toc-number">3.2.</span> <span class="toc-text">2.2 空间卷积网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-CNN-近期发展中的关键架构"><span class="toc-number">3.2.1.</span> <span class="toc-text">2.2.1 CNN 近期发展中的关键架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-实现-CNN-的不变性"><span class="toc-number">3.2.2.</span> <span class="toc-text">2.2.2 实现 CNN 的不变性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-3-实现-CNN-的定位"><span class="toc-number">3.2.3.</span> <span class="toc-text">2.2.3 实现 CNN 的定位</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-时空卷积网络"><span class="toc-number">3.3.</span> <span class="toc-text">2.3 时空卷积网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-1-基于-LSTM-的时空-CNN"><span class="toc-number">3.3.1.</span> <span class="toc-text">2.3.1 基于 LSTM 的时空 CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-2-3D-CNN"><span class="toc-number">3.3.2.</span> <span class="toc-text">2.3.2 3D CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-3-Two-Stream-CNN"><span class="toc-number">3.3.3.</span> <span class="toc-text">2.3.3 Two-Stream CNN</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-总体讨论"><span class="toc-number">3.4.</span> <span class="toc-text">2.4 总体讨论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-理解-CNN-的构建模块"><span class="toc-number">4.</span> <span class="toc-text">3 理解 CNN 的构建模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-卷积层"><span class="toc-number">4.1.</span> <span class="toc-text">3.1 卷积层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-整流"><span class="toc-number">4.2.</span> <span class="toc-text">3.2 整流</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-归一化"><span class="toc-number">4.3.</span> <span class="toc-text">3.3 归一化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-池化"><span class="toc-number">4.4.</span> <span class="toc-text">3.4 池化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-总体讨论"><span class="toc-number">4.5.</span> <span class="toc-text">3.5 总体讨论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-当前状态"><span class="toc-number">5.</span> <span class="toc-text">4 当前状态</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-当前趋势"><span class="toc-number">5.1.</span> <span class="toc-text">4.1 当前趋势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-仍待解决的问题"><span class="toc-number">5.2.</span> <span class="toc-text">4.2 仍待解决的问题</span></a></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片1.png)"><div id="post-info"><div id="post-title"><div class="posttitle">论文阅读：What Do We Understand About Convolutional Networks？ 对卷积的了解</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-07-31<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-07-31</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%91%A8%E9%83%B4%E8%8E%B2/">周郴莲</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%91%A8%E9%83%B4%E8%8E%B2/NLP/">NLP</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">8.5k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 26 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h2 id="What-Do-We-Understand-About-Convolutional-Networks"><a href="#What-Do-We-Understand-About-Convolutional-Networks" class="headerlink" title="What Do We Understand About Convolutional Networks?"></a>What Do We Understand About Convolutional Networks?</h2><h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul>
<li><a href="#id1">1 引言</a><ul>
<li><a href="#id11">1.1 动机</a></li>
<li><a href="#id12">1.2 目标</a></li>
<li><a href="#id13">1.3 报告提纲</a></li>
</ul>
</li>
<li><a href="#id2">2 多层网络</a><ul>
<li><a href="#id21">2.1 多层架构</a><ul>
<li><a href="#id211">2.1.1 神经网络</a></li>
<li><a href="#id212">2.1.2 循环神经网络</a></li>
<li><a href="#id213">2.1.3 卷积网络</a></li>
<li><a href="#id214">2.1.4 生成对抗网络</a></li>
<li><a href="#id215">2.1.5 多层网络训练</a></li>
<li><a href="#id216">2.1.6 简单说说迁移学习</a></li>
</ul>
</li>
<li><a href="#id22">2.2 空间卷积网络</a><ul>
<li><a href="#id221">2.2.1 CNN近期发展中的关键架构</a></li>
<li><a href="#id222">2.2.2 实现CNN的不变性</a></li>
<li><a href="#id223">2.2.3 实现CNN的定位</a></li>
</ul>
</li>
<li><a href="#id23">2.3 时空卷积网络</a><ul>
<li><a href="#id231">2.3.1 基于LSTM的时空CNN</a></li>
<li><a href="#id232">2.3.2 3D CNN</a></li>
<li><a href="#id233">2.3.3 Two-Stream CNN</a></li>
</ul>
</li>
<li><a href="#id24">2.4 总体讨论</a></li>
</ul>
</li>
<li><a href="#id3">3 理解CNN的构建模块</a><ul>
<li><a href="#id31">3.1 卷积层</a></li>
<li><a href="#id32">3.2 整流</a></li>
<li><a href="#id33">3.3 归一化</a></li>
<li><a href="#id34">3.4 池化</a></li>
<li><a href="#id35">3.5 总体讨论</a></li>
</ul>
</li>
<li><a href="#id4">4 当前状态</a><ul>
<li><a href="#id41">4.1 当前趋势</a></li>
<li><a href="#id42">4.2 仍待解决的问题</a></li>
</ul>
</li>
</ul>
<p>&emsp;&emsp;<font color="#dddd00"><strong>卷积神经网络</strong></font>（CNN）最开始是用于<strong>计算机视觉</strong>中，然而现在也被广泛用于<strong>自然语言处理</strong>中，而且有着不亚于RNN（<font color="#dddd00"><strong>循环神经网络</strong></font>）的性能，但我们目前对其效果显著的原因还没有全面的理解。<strong>2015年以来</strong>，有关深度学习在NLP领域的论文层出不穷。尽管其中必定有很多附庸风雅的水文，但是也存在很多经典的应用型文章。<strong>2018年3月，约克大学电气工程与计算机科学系的 Isma Hadji 和 Richard P. Wildes</strong>发表了论文<a href="https://arxiv.org/pdf/1803.08834.pdf" target="_blank" rel="noopener"><font color="#dddd00"><strong>《What Do We Understand About Convolutional Networks?》</strong></font></a>，对卷积网络的<strong>技术基础、组成模块、现状和研究前景</strong>进行了梳理，介绍了我们当前对<strong>CNN的理解</strong>。本文对该论文进行了摘要式的编译，更详细的信息请参阅原论文及其中索引的相关文献。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片1.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图1" class="fancybox"><img alt="图1" title="图1" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片1.png" class="lazyload"></a></p>
<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 <span id="id1">引言</span></h2><h3 id="1-1-动机"><a href="#1-1-动机" class="headerlink" title="1.1 动机"></a>1.1 <span id="id11">动机</span></h3><p>&emsp;&emsp;过去几年来，计算机视觉研究主要集中在<strong>卷积神经网络</strong>（常简称为ConvNet或CNN）上。这些工作已经在广泛的<strong>分类和回归</strong>任务上实现了新的当前最佳表现。相对而言，尽管这些方法的历史可以追溯到多年前，但对这些系统得到出色结果的方式的理论理解还很滞后。事实上，当前计算机视觉领域的很多成果都是将 CNN 当作黑箱使用，这种做法是有效的，但其有效的原因却非常模糊不清，这严重满足不了科学研究的要求。尤其是这两个可以互补的问题：<font color="#dddd00"><strong>（1）在被学习的方面（比如卷积核），究竟被学习的是什么？（2）在架构设计方面（比如层的数量、核的数量、池化策略、非线性的选择），为什么某些选择优于另一些选择？</strong></font>这些问题的答案不仅有利于提升我们对 CNN 的科学理解，而且还能提升它们的实用性。<br>&emsp;&emsp;此外，目前实现 <strong>CNN 的方法需要大量训练数据</strong>，而且设计决策对结果表现有很大的影响。更深度的理论理解应该能减轻对数据驱动的设计的依赖。尽管已有实证研究调查了所实现的网络的运行方式，但到目前为止，这些结果很大程度上还局限在内部处理过程的可视化上，目的是为了理解 CNN 中不同层中发生的情况。</p>
<h3 id="1-2-目标"><a href="#1-2-目标" class="headerlink" title="1.2 目标"></a>1.2 <span id="id12">目标</span></h3><p>&emsp;&emsp;针对上述情况，本报告将概述研究者提出的最突出的使用<strong>多层卷积架构的方法</strong>。要重点指出的是，本报告将通过概述不同的方法来讨论典型卷积网络的各种组件，并将介绍它们的设计决策所基于的生物学发现和/或合理的理论基础。此外，本报告还将概述通过<strong>可视化和实证研究来理解 CNN 的不同尝试</strong>。本报告的最终目标是阐释 CNN 架构中涉及的每一个处理层的作用，汇集我们当前对 CNN 的理解以及说明仍待解决的问题。</p>
<h3 id="1-3-报告提纲"><a href="#1-3-报告提纲" class="headerlink" title="1.3 报告提纲"></a>1.3 <span id="id13">报告提纲</span></h3><p>&emsp;&emsp;本报告的结构如下：<font color="#dddd00"><strong>本章</strong></font>给出了回顾我们<strong>对卷积网络的理解的动机</strong>。<font color="#dddd00"><strong>第 2 章</strong></font>将描述<strong>各种多层网络并给出计算机视觉应用中使用的最成功的架构</strong>。<font color="#dddd00"><strong>第 3 章</strong></font>将更具体地关注<strong>典型卷积网络的每种构造模块</strong>，并将从生物学和理论两个角度讨论不同组件的设计。最后，<font color="#dddd00"><strong>第 4 章</strong></font>将会讨论 <strong>CNN 设计的当前趋势以及理解 CNN 的工作</strong>，并且还将重点说明仍然存在的一些关键短板。</p>
<h2 id="2-多层网络"><a href="#2-多层网络" class="headerlink" title="2 多层网络"></a>2 <span id="id2">多层网络</span></h2><p>&emsp;&emsp;总的来说，本章将简要<strong>概述计算机视觉领域中所用的最突出的多层架构</strong>。需要指出，尽管本章涵盖了文献中最重要的贡献，但却不会对这些架构进行全面概述，因为其它地方已经存在这样的概述了（比如 <strong>[17, 56, 90]</strong>）。相反，本章的目的是为本报告的剩余部分设定讨论基础，以便我们<strong>详细展示和讨论当前对用于视觉信息处理的卷积网络的理解</strong>。</p>
<h3 id="2-1-多层架构"><a href="#2-1-多层架构" class="headerlink" title="2.1 多层架构"></a>2.1 <span id="id21">多层架构</span></h3><p>&emsp;&emsp;在近来基于深度学习的网络取得成功之前，最先进的用于识别的计算机视觉系统依赖于两个分离但又互补步骤。<font color="#dddd00"><strong>第一步是通过一组人工设计的操作（比如与基本集的卷积、局部或全局编码方法）将输入数据变换成合适的形式</strong></font>。对输入的变换通常需要找到输入数据的一种紧凑和/或抽象的表征，同时还要根据当前任务注入一些不变量。这种变换的目标是以一种更容易被分类器分离的方式改变数据。其次，<font color="#dddd00"><strong>被变换的数据通常用于训练某些类型的分类器（比如支持向量机）来识别输入信号的内容</strong></font>。通常而言，任何分类器的表现都会受到所使用的变换方法的严重影响。<br>&emsp;&emsp;多层学习架构为这一问题带来了不同的前景，这种架构提出不仅要学习分类器，而且要从数据中直接学习所需的变换操作。这种形式的学习通常被称为<font color="#dddd00"><strong>「表征学习」</strong></font>，当应用在深度多层架构中时即被称为<font color="#dddd00"><strong>「深度学习」</strong></font>。<br>&emsp;&emsp;多层架构可以定义为允许从输入数据的多层抽象中提取有用信息的计算模型。一般而言，<strong>多层架构的设计目标是在更高层凸显输入中的重要方面，同时能在遇到更不重要的变化时变得越来越稳健</strong>。大多数多层架构都是将带有交替的线性和非线性函数的简单构建模块堆叠在一起。多年以来，研究者已经提出了很多不同类型的多层架构，本章将会覆盖<strong>计算机视觉应用中所采用的最为突出的此类架构</strong>。<font color="#dddd00"><strong>人工神经网络</strong></font>是其中的关注重点，因为这种架构的表现非常突出。为了简单起见，后面会直接将这类网络称为<font color="#dddd00"><strong>「神经网络」</strong></font>。</p>
<h4 id="2-1-1-神经网络"><a href="#2-1-1-神经网络" class="headerlink" title="2.1.1 神经网络"></a>2.1.1 <span id="id211">神经网络</span></h4><p>&emsp;&emsp;<strong>典型的神经网络由一个输入层、一个输出层和多个隐藏层构成，其中每一层都包含多个单元</strong>。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片2.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图2" class="fancybox"><img alt="图2" title="图2" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片2.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.1：典型神经网络架构示意图，图来自 [17]*</font>

<p>&emsp;&emsp;<font color="#dddd00"><strong>自动编码器</strong></font>可以定义为由两个主要部分构成的多层神经网络。<strong>第一个部分是编码器，可以将输入数据变换成特征向量；第二个部分是解码器，可将生成的特征向量映射回输入空间</strong>。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片3.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图3" class="fancybox"><img alt="图3" title="图3" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片3.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.2：典型自动编码器网络的结构，图来自 [17]*</font>

<h4 id="2-1-2-循环神经网络"><a href="#2-1-2-循环神经网络" class="headerlink" title="2.1.2 循环神经网络"></a>2.1.2 <span id="id212">循环神经网络</span></h4><p>&emsp;&emsp;当谈到依赖于序列输入的任务时，<font color="#dddd00"><strong>循环神经网络</strong></font>（RNN）是最成功的多层架构之一。RNN 可被视为一种特殊类型的神经网络，其中<strong>每个隐藏单元的输入时其当前时间步骤观察到的数据和其前一个时间步骤的状态</strong>。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片4.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图4" class="fancybox"><img alt="图4" title="图4" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片4.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.3：标准循环神经网络的运算的示意图。每个 RNN 单元的输入都是当前时间步骤的新输入和前一个时间步骤的状态；然后根据计算得到新输出，这个输出又可被馈送到多层 RNN 的下一层进行处理。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片5.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图5" class="fancybox"><img alt="图5" title="图5" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片5.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.4：典型 LSTM 单元示意图。该单元的输入是当前时间的输入和前一时间的输入，然后它会返回一个输出并将其馈送给下一时间。LSTM 单元的最终输出由输入门、输出门和记忆单元状态控制。图来自 [33]*</font>

<h4 id="2-1-3-卷积网络"><a href="#2-1-3-卷积网络" class="headerlink" title="2.1.3 卷积网络"></a>2.1.3 <span id="id213">卷积网络</span></h4><p>&emsp;&emsp;<font color="#dddd00"><strong>卷积网络</strong></font>（CNN）是一类尤其适合计算机视觉应用的神经网络，因为它们能使用局部操作对表征进行分层抽象。有两大关键的设计思想推动了卷积架构在计算机视觉领域的成功。<strong>第一，CNN 利用了图像的 2D 结构，并且相邻区域内的像素通常是高度相关的</strong>。因此，CNN 就无需使用所有像素单元之间的一对一连接（大多数神经网络都会这么做），而可以使用分组的局部连接。<strong>第二，CNN 架构依赖于特征共享，因此每个通道（即输出特征图）是在所有位置使用同一个过滤器进行卷积而生成的</strong>。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片6.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图6" class="fancybox"><img alt="图6" title="图6" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片6.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.5：标准卷积网络的结构的示意图，图来自 [93]*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片7.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图7" class="fancybox"><img alt="图7" title="图7" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片7.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.6：Neocognitron 的结构示意图，图来自 [49]*</font>

<h4 id="2-1-4-生成对抗网络"><a href="#2-1-4-生成对抗网络" class="headerlink" title="2.1.4 生成对抗网络"></a>2.1.4 <span id="id214">生成对抗网络</span></h4><p>&emsp;&emsp;典型的<font color="#dddd00"><strong>生成对抗网络</strong></font>（GAN）由两个互相竞争的模块或子网络构成，即：<strong>生成器网络和鉴别器网络</strong>。<br><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片8.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图8" class="fancybox"><img alt="图8" title="图8" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片8.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.7：生成对抗网络的一般结构的示意图*</font>

<h4 id="2-1-5-多层网络的训练"><a href="#2-1-5-多层网络的训练" class="headerlink" title="2.1.5 多层网络的训练"></a>2.1.5 <span id="id215">多层网络的训练</span></h4><p>&emsp;&emsp;如前面讨论的一样，多种多层架构的成功都很大程度上取决于它们的学习过程的成功。其训练过程通常都<strong>基于使用梯度下降的误差的反向传播</strong>。由于使用简单，梯度下降在训练多层架构上有广泛的应用。</p>
<h4 id="2-1-6-简单说说迁移学习"><a href="#2-1-6-简单说说迁移学习" class="headerlink" title="2.1.6 简单说说迁移学习"></a>2.1.6 <span id="id216">简单说说迁移学习</span></h4><p>&emsp;&emsp;使用多层架构提取的特征在多种不同数据集和任务上的适用性可以归功于它们的<strong>分层性质</strong>，<strong>表征</strong>会在这样的结构中从简单和局部向抽象和全局发展。因此，在其层次结构中的低层级提取的特征往往是多种不同任务共有的特征，因此使得<strong>多层结构更容易实现迁移学习</strong>。</p>
<h3 id="2-2-空间卷积网络"><a href="#2-2-空间卷积网络" class="headerlink" title="2.2 空间卷积网络"></a>2.2 <span id="id22">空间卷积网络</span></h3><p>&emsp;&emsp;理论上而言，卷积网络可以应用于任意维度的数据。它们的二维实例非常适用于单张图像的结构，因此在计算机视觉领域得到了相当大的关注。有了大规模数据集和强大的计算机来进行训练之后，CNN 近来在多种不同任务上的应用都出现了迅猛增长。本节将介绍为原来的 <font color="#dddd00"><strong>LeNet</strong></font> 引入了相对新颖的组件的比较突出的 <font color="#dddd00"><strong>2D CNN</strong></font> 架构。</p>
<h4 id="2-2-1-CNN-近期发展中的关键架构"><a href="#2-2-1-CNN-近期发展中的关键架构" class="headerlink" title="2.2.1 CNN 近期发展中的关键架构"></a>2.2.1 <span id="id221">CNN 近期发展中的关键架构</span></h4><p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片9.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图9" class="fancybox"><img alt="图9" title="图9" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片9.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.8：AlexNet 架构。需要指出，虽然从图上看这是一种有两个流的架构，但实际上这是一种单流的架构，这张图只是说明 AlexNet 在 2 个不同 GPU 上并行训练的情况。图来自 [88]*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片10.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图10" class="fancybox"><img alt="图10" title="图10" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片10.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.9：GoogLeNet 架构。（a）典型的 inception 模块，展示了顺序和并行执行的操作。（b）由层叠的许多 inception 模块构成的典型 inception 架构的示意图。图来自 [138]*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片11.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图11" class="fancybox"><img alt="图11" title="图11" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片11.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.10：ResNet 架构。（a）残差模块。（b）由层叠的许多残差模块构成的典型 ResNet 架构示意图。图来自 [64]*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片12.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图12" class="fancybox"><img alt="图12" title="图12" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片12.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.11：DenseNet 架构。（a）dense 模块。（b）（b）由层叠的许多 dense 模块构成的典型 DenseNet 架构的示意图。图来自 [72]*</font>

<h4 id="2-2-2-实现-CNN-的不变性"><a href="#2-2-2-实现-CNN-的不变性" class="headerlink" title="2.2.2 实现 CNN 的不变性"></a>2.2.2 <span id="id222">实现 CNN 的不变性</span></h4><p>&emsp;&emsp;使用 CNN 的一大难题是需要<strong>非常大的数据集</strong>来学习所有的基本参数。甚至<strong>拥有超过 100 万张图像的 ImageNet 等大规模数据集在训练特定的深度架构时仍然被认为太小</strong>。满足这种大数据集要求的一种方法是人工增强数据集，具体做法包括对图像进行<strong>随机翻转、旋转和抖动</strong>（jittering）等。这些增强方法的一大优势是能让所得到的网络在面对各种变换时能更好地保持不变。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片13.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图13" class="fancybox"><img alt="图13" title="图13" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片13.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.12:空间变压器网络运行。(a)对空间变压器模块的描述，典型的变换操作如(b)所示。图来自[76]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片14.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图14" class="fancybox"><img alt="图14" title="图14" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片14.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 2.13:可变或动态卷积。从一个固定的窗口大小开始，网络通过一个小的子网(如图上方绿色部分所示)学习偏移量，最后对一个可变的窗口进行卷积。图来自[29]。*</font>

<h4 id="2-2-3-实现-CNN-的定位"><a href="#2-2-3-实现-CNN-的定位" class="headerlink" title="2.2.3 实现 CNN 的定位"></a>2.2.3 <span id="id223">实现 CNN 的定位</span></h4><p>&emsp;&emsp;除了识别物体等简单的分类任务，CNN 近来也在需要精准定位的任务上表现出色，比如<strong>形义分割和目标检测</strong>。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片15.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图15" class="fancybox"><img alt="图15" title="图15" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片15.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图2.14：全卷积网络。经过上采样以恢复最后一层的图像全分辨率后，使用softmax对每个像素进行分类以最终生成段。图来自[98]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片16.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图16" class="fancybox"><img alt="图16" title="图16" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片16.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图2.15：主要区域提案网络的进度。（a）原始R-CNN的结构。图来自[53]。 （b）快速R-CNN的结构。图来自[52]。 （c）更快的R-CNN的结构。图来自[116]。（d）掩模R-CNN的结构。图来自[61]。*</font>

<h3 id="2-3-时空卷积网络"><a href="#2-3-时空卷积网络" class="headerlink" title="2.3 时空卷积网络"></a>2.3 <span id="id23">时空卷积网络</span></h3><p>&emsp;&emsp;使用 <strong>CNN 为各种基于图像的应用</strong>带来了显著的性能提升，也催生了研究者将 2D 空间 CNN 扩展到视频分析的 3D 时空 CNN 上的兴趣。一般而言，文献中提出的各种时空架构都只是试图将空间域 (x,y) 的 2D 架构扩展到时间域 (x, y, t) 中。在基于训练的时空 CNN 领域存在 3 种比较突出的不同架构设计决策：<font color="#dddd00"><strong>基于 LSTM 的 CNN、3D CNN 和 Two-Stream CNN</strong></font>。</p>
<h4 id="2-3-1-基于-LSTM-的时空-CNN"><a href="#2-3-1-基于-LSTM-的时空-CNN" class="headerlink" title="2.3.1 基于 LSTM 的时空 CNN"></a>2.3.1 <span id="id231">基于 LSTM 的时空 CNN</span></h4><p>&emsp;&emsp;<font color="#dddd00"><strong>基于 LSTM 的时空 CNN</strong></font> 是将 2D 网络扩展成能处理时空数据的一些早期尝试。它们的操作可以总结成<font color="#dddd00"><strong>图 2.16</strong></font> 所示的三个步骤。<strong>第一步，使用一个 2D 网络处理每一帧，并从这些 2D 网络的最后一层提取出特征向量。第二步，将这些来自不同时间步骤的特征用作 LSTM 的输入，得到时间上的结果。第三步，再对这些结果求平均或线性组合，然后再传递给一个 softmax 分类器以得到最终预测</strong>。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片17.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图17" class="fancybox"><img alt="图17" title="图17" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片17.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图2.16：基于LSTM的时空ConvNet示例。在该网络中，输入由来自视频流的连续帧组成。图转载自[33]。*</font>

<h4 id="2-3-2-3D-CNN"><a href="#2-3-2-3D-CNN" class="headerlink" title="2.3.2 3D CNN"></a>2.3.2 <span id="id232">3D CNN</span></h4><p>&emsp;&emsp;这种突出的<font color="#dddd00"><strong>时空网络</strong></font>是将 <strong>2D CNN 最直接地泛化到图像时空域中</strong>。它直接处理 <strong>RGB 图像的时间流</strong>，并通过应用所学习到的 <strong>3D 卷积过滤器</strong>来处理这些图像。</p>
<h4 id="2-3-3-Two-Stream-CNN"><a href="#2-3-3-Two-Stream-CNN" class="headerlink" title="2.3.3 Two-Stream CNN"></a>2.3.3 <span id="id233">Two-Stream CNN</span></h4><p>&emsp;&emsp;这种类型的时空架构依赖于一种<font color="#dddd00"><strong>双流式</strong></font>（two-stream）的设计。标准的双流式架构是采用两个并行通路——<strong>一个用于处理外观，另一个用于处理运动</strong>；这种方法类似于生物视觉系统研究中的双流式假设。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片18.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图18" class="fancybox"><img alt="图18" title="图18" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片18.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图2.17：原始的两流网络。该网络将RGB帧和光流堆栈作为输入。图摘自[134]。*</font>

<h3 id="2-4-总体讨论"><a href="#2-4-总体讨论" class="headerlink" title="2.4 总体讨论"></a>2.4 <span id="id24">总体讨论</span></h3><p>&emsp;&emsp;总的来说，尽管处理多层网络的文献非常多，每个派别都主张一种架构优于另一种架构，但一些常见的“<strong>最佳实践</strong>”已经出现。突出的例子包括:大多数架构依赖于四种常见的构建模块(即<font color="#dddd00"><strong>卷积、整流、归一化和池化</strong></font>)，具有小支持<strong>卷积内核的深层架构</strong>对于在可管理的参数数量下实现抽象的重要性，剩余连接用于应对学习过程中错误梯度传播的挑战。更普遍的是，文献同意输入数据的良好表示是分层的这一关键观点，如前面的几个贡献中所指出的[119]。<br>&emsp;&emsp;需要重点指出的是，尽管这些网络在很多计算机视觉应用上都实现了很有竞争力的结果，但它们的<strong>主要缺点</strong>仍然存在：<font color="#dddd00"><strong>对所学习到的表征的确切本质的理解很有限、依赖于大规模数据训练集、缺乏支持准确的表现边界的能力、网络超参数选择不清晰</strong></font>。</p>
<h2 id="3-理解-CNN-的构建模块"><a href="#3-理解-CNN-的构建模块" class="headerlink" title="3 理解 CNN 的构建模块"></a>3 <span id="id3">理解 CNN 的构建模块</span></h2><p>&emsp;&emsp;鉴于 CNN 领域存在大量悬而未决的问题，本章将<strong>介绍典型卷积网络中每种处理层的作用和意义</strong>。为此本章将概述在解决这些问题上最突出的工作。尤其值得一提的是，我们将从理论和生物学两个角度来展示 CNN 组件的建模方式。每种组件的介绍后面都总结了我们当前的理解水平。</p>
<h3 id="3-1-卷积层"><a href="#3-1-卷积层" class="headerlink" title="3.1 卷积层"></a>3.1 <span id="id31">卷积层</span></h3><p>&emsp;&emsp;卷积层可以说是 CNN 架构中最重要的步骤之一。基本而言，<strong>卷积是一种线性的、平移不变性的运算，其由在输入信号上执行局部加权的组合构成</strong>。根据所选择的权重集合（即所选择的<font color="#dddd00"><strong>点扩散函数</strong></font>（point spread function））的不同，也将揭示出输入信号的不同性质。在频率域中，与点扩散函数关联的是调制函数——<strong>说明了输入的频率组分通过缩放和相移进行调制的方式。因此，选择合适的核（kernel）对获取输入信号中所包含的最显著和最重要的信息而言至关重要，这能让模型对该信号的内容做出更好的推断</strong>。本节将讨论一些实现这个核选择步骤的不同方法。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片19.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图19" class="fancybox"><img alt="图19" title="图19" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片19.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.1：HMAX模型图该模型由具有交替的简单（S）和复杂（C）单元的单元层次组成。过滤操作发生在S单元的级别。在该图中示出，在初始层（S1）处的简单单元检测到简单的定向条（即，通过使用定向的Gabor滤波器）。另一方面，较高层（S2）的简单单元使用模板进行响应，该模板是在先前（S1）层使用的过滤器的组合，因此层次结构中较高层的单元比定向条检测到更复杂的形状。复杂的复合单元格（C1，C2）插在简单单元格的各层之间，以在空间位置上聚集相似调整的单元格，从而实现一定程度的移位不变性。图转自[117]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片20.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图20" class="fancybox"><img alt="图20" title="图20" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片20.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.2：Serre等人提出的网络架构。与HMAX模型[117]相似，它由交替的简单和复杂单元组成，因此，所提出网络的总体架构可以概括为S1→C1→S2→C2。但是，与HMAX模型相反，在S2单元级别使用的模板是从训练集中显式学习的，因此该层可以检测到复杂的对象（即，在使用对象识别数据集进行训练时）。该过程的详细信息汇总在该图的第二行。图转载自[131]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片21.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图21" class="fancybox"><img alt="图21" title="图21" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片21.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.3：由多层体系结构学习的示例部分，由Fidler等人提出。第一行（从左到右）：第2层和第3层示例部分。第二和第三行：使用面部，汽车和杯子学习的第4层和第5层部分。图转载自[47]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片22.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图22" class="fancybox"><img alt="图22" title="图22" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片22.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.4：CNN接收（也称为RFNN）的示意图。在该网络中，（通过学习）将所有层使用的滤波器构建为基本滤波器组φm的线性组合，基本滤波器组是一组n阶高斯导数。该网络不是学习过滤器的内核参数，而是学习用于线性组合基本组中的过滤器的参数αij。图转载自[75]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片23.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图23" class="fancybox"><img alt="图23" title="图23" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片23.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.5：散射变换网络。在这个网络中，在[15]中提出的散射变换S [λ] x重复地应用于来自上一层的所有输出U [λi] x的每一层m。本质上，每一层的输出都一遍又一遍地经过相同的变换，但是，该变换针对每一层的不同有效频率，从而在每一层提取新颖的信息。在该图中，以m = 3层的网络实例化为例。图转载自[15]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片24.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图24" class="fancybox"><img alt="图24" title="图24" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片24.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.6：SOE-Net架构使用初始处理层Lk提取各个方向的局部时空特征。 C-R-N-S表示卷积、校正、规范化和时空合并，而R和L分别表示向右过滤过滤数据和向左过滤的数据，其中符号字符串（例如LR）表示多个过滤。为了说明，示出了仅具有2个滤波器（即2个方向）的网络。 Lkis层上的每个特征图均被视为新的单独信号，并反馈到Lk + 1层，以使用同一组滤波器进行卷积，但由于时空合并而具有不同的有效分辨率。图转载自[60]。*</font>

<h3 id="3-2-整流"><a href="#3-2-整流" class="headerlink" title="3.2 整流"></a>3.2 <span id="id32">整流</span></h3><p>&emsp;&emsp;多层网络通常是高度非线性的，而<font color="#dddd00"><strong>整流</strong></font>（rectification）则通常是将<strong>非线性引入模型的第一个处理阶段</strong>。整流是指<strong>将点方面的非线性（也被称为激活函数）应用到卷积层的输出上</strong>。这一术语借用自信号处理领域，其中整流是指将交流变成<font color="#dddd00"><strong>直流</strong></font>。这也是一个能从生物学和理论两方面都找到起因的处理步骤。计算神经科学家引入整流步骤的<font color="#dddd00"><strong>目的</strong></font>是<strong>寻找能最好地解释当前神经科学数据的合适模型</strong>。<strong>另一方面，机器学习研究者使用整流的目的是为了让模型能更快和更好地学习</strong>。有趣的是，这两个方面的研究者往往都认同这一点：他们不仅需要整流，而且还会殊途同归到同一种整流上。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片25.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图25" class="fancybox"><img alt="图25" title="图25" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片25.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.7：多层网络的文献中所使用的非线性整流函数*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片26.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图26" class="fancybox"><img alt="图26" title="图26" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片26.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.8：AlexNet学习的Conv1过滤器的可视化在ImageNet数据集上受过训练。图来自[132]。*</font>

<h3 id="3-3-归一化"><a href="#3-3-归一化" class="headerlink" title="3.3 归一化"></a>3.3 <span id="id33">归一化</span></h3><p>&emsp;&emsp;正如前面提到的，由于这些网络中存在级联的非线性运算，所以多层架构是高度非线性的。除了前一节讨论的<strong>整流非线性</strong>，<font color="#dddd00"><strong>归一化</strong></font>（normalization）是 CNN 架构中有重要作用的又一种非线性处理模块。CNN 中最广泛使用的归一化形式是所谓的 <font color="#dddd00"><strong>Divisive Normalization</strong></font>（DN，也被称为<strong>局部响应归一化</strong>）。本节将介绍归一化的作用并描述其纠正前两个处理模块（<strong>卷积和整流</strong>）的缺点的方式。同样，我们会从生物学和理论两个方面讨论归一化。</p>
<h3 id="3-4-池化"><a href="#3-4-池化" class="headerlink" title="3.4 池化"></a>3.4 <span id="id34">池化</span></h3><p>&emsp;&emsp;不管是生物学启发的，还是纯粹基于学习的或完全人工设计的，几乎所有 CNN 模型都包含池化步骤。<font color="#dddd00"><strong>池化运算的目标</strong></font>是<strong>为位置和尺寸的改变带来一定程度的不变性以及在特征图内部和跨特征图聚合响应</strong>。与之前几节讨论的三种 CNN 模块类似，池化在生物学和理论研究上都具有支持。在 CNN 网络的这个处理层上，主要的争论点是<font color="#dddd00"><strong>池化函数的选择</strong></font>。使用最广泛的两种池化函数分别是<font color="#dddd00"><strong>平均池化和最大池化</strong></font>。本节将探索相关文献中描述的各种池化函数的优点和缺点。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片27.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图27" class="fancybox"><img alt="图27" title="图27" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片27.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.9：简单单元与复杂单元之间的差异示意图。该图表明，复杂细胞应答是由简单细胞应答的组合产生的。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片28.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图28" class="fancybox"><img alt="图28" title="图28" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片28.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图 3.10：平均池化和最大池化在 Gabor 滤波后的图像上的比较。（a）展示了不同尺度的平均池化的效果，其中（a）中上面一行是应用于原始灰度值图像的结果，（a）中下面一行是应用于 Gabor 滤波后的图像上的结果。平均池化能得到灰度值图像的更平滑的版本，而稀疏的 Gabor 滤波后的图像则会褪色消散。相对而言，（b）给出了不同尺度的最大池化的效果，其中（b）中上面一行是应用于原始灰度值图像的结果，（b）中下面一行是应用于 Gabor 滤波后的图像上的结果。这里可以看到，最大池化会导致灰度值图像质量下降，而 Gabor 滤波后的图像中的稀疏边则会得到增强。图来自 [131]*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片29.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图29" class="fancybox"><img alt="图29" title="图29" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片29.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.11：跨通道合并插图。 （左）Gabor滤波器的滤波操作调整到各种方向后产生的密集简单单元格响应（此处出于说明目的显示了4个方向）（右）使用max运算符（即每个像素）的跨通道合并导致的稀疏简单单元格响应位置，将保留整个要素地图的最大响应）。图转载自[110]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片30.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图30" class="fancybox"><img alt="图30" title="图30" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片30.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.12：混合、门控和树池化。所描述的（a）混合最大平均池，（b）门控最大平均池和（c）树池的图示。图转载自[95]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片31.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图31" class="fancybox"><img alt="图31" title="图31" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片31.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图3.13：空间金字塔池网络。 SPP应用于网络的最后卷积层的特征图。由于空间仓与图像大小成正比，因此SPP生成与输入图像大小无关的相同大小的特征向量。因此，SPP-Net不需要对输入图像进行相同大小的预处理。图转载自[62]。*</font>

<h3 id="3-5-总体讨论"><a href="#3-5-总体讨论" class="headerlink" title="3.5 总体讨论"></a>3.5 <span id="id35">总体讨论</span></h3><p>&emsp;&emsp;本章讨论了<font color="#dddd00"><strong>典型ConvNet体系结构</strong></font>中<strong>最广泛使用的构建块的作用和重要性</strong>，<strong>以努力理解ConvNet的工作原理</strong>。特别是，<strong>每个区块的细节都从生物学和理论的角度进行了阐述</strong>。总的来说，在探索所讨论的构建块的过程中出现了各种常见的线程。特别地，似乎所有的阻滞都从发生在视觉皮层的操作中找到了相对强烈的动机。此外，尽管所有的块在ConvNets中都扮演着重要的角色，但卷积核的选择似乎是最重要的方面，这一点在处理这个块的大量文献中得到了证明。更重要的是，本章中讨论的<strong>最近的ConvNet架构</strong>(例如[15,28,60,75,148])旨在通过在其网络的不同阶段合并更多可控制的构建块，将对基于训练的解决方案的需求最小化。通过分层可视化和消融研究，揭示了<strong>基于学习的卷积神经网络的次优性</strong>(例如，一些广泛使用的已学卷积神经网络的主要冗余)，这些最近的方法反过来受到了各种努力的推动，这些研究将在下一章讨论。</p>
<h2 id="4-当前状态"><a href="#4-当前状态" class="headerlink" title="4 当前状态"></a>4 <span id="id4">当前状态</span></h2><p>&emsp;&emsp;对 CNN 架构中各种组件的作用的论述凸显了卷积模块的重要性，这个模块很大程度上负责了在网络中获取最抽象的信息。相对而言，我们对这个处理模块的理解却最少，因为这需要最繁重的计算。本章将介绍在尝试理解<strong>不同的 CNN 层所学习的内容上的当前趋势</strong>。同时，我们还将重点说明这些趋势方面仍<strong>有待解决的问题</strong>。</p>
<h3 id="4-1-当前趋势"><a href="#4-1-当前趋势" class="headerlink" title="4.1 当前趋势"></a>4.1 <span id="id41">当前趋势</span></h3><p>&emsp;&emsp;尽管各种 CNN 模型仍继续在多种计算机视觉应用中进一步推进当前最佳的表现，但在理解这些系统的工作方式和如此有效的原因上的进展仍还有限。这个问题已经引起了很多研究者的兴趣，为此也涌现出了很多用于理解 CNN 的方法。一般而言，这些方法可以分成<strong>三个方向</strong>：<font color="#dddd00"><strong>对所学习到的过滤器和提取出的特征图进行可视化、受理解视觉皮层的生物学方法启发的 ablation study、通过向网络设计中引入分析原理来最小化学习过程</strong></font>。本节将简要概述其中每种方法。</p>
<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片32.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图32" class="fancybox"><img alt="图32" title="图32" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片32.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图4.1：DeConvNet构建块（a）说明了一个DeConvNet操作，该操作可用于将从ConvNet的任何层提取的特征图投影回图像空间。 （b）举例说明通过使用“switches”进行的“分池”操作，这些switches对应于响应最大池化操作的位置。图转自[154]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片33.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图33" class="fancybox"><img alt="图33" title="图33" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片33.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图4.2：通过在标准ConvNet体系结构的各个层（例如AlexNet [88]）应用DeconvNet获得的可视化效果。图转自[154]。*</font>

<p><a href="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片34.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="图34" class="fancybox"><img alt="图34" title="图34" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.3/img/周郴莲/7.31/图片34.png" class="lazyload"></a></p>
<font face="宋体" size="1">*图4.3：通过以网络为中心的方法在图像空间中应用优化获得的可视化效果。 （a）通过最大化属于各种类别的得分获得的可视化效果，如下图所示。图转载自[133]。 （b）通过最大化标准网络在各个层的响应而获得的可视化效果，如每个图像下方所示。图转载自[104]。*</font>

<h3 id="4-2-仍待解决的问题"><a href="#4-2-仍待解决的问题" class="headerlink" title="4.2 仍待解决的问题"></a>4.2 <span id="id42">仍待解决的问题</span></h3><p>&emsp;&emsp;基于上述讨论，基于可视化的方法存在以下<strong>关键研究方向</strong>：</p>
<blockquote>
<ul>
<li>首要的一点：<font color="#dddd00"><strong>开发使可视化评估更为客观的方法</strong></font>是非常重要的，可以通过<strong>引入评估所生成的可视化图像的质量和/或含义的指标来实现</strong>。</li>
<li>另外，尽管看起来以<font color="#dddd00"><strong>网络</strong></font>为中心的可视化方法更有前景（因为它们在生成可视化结果上不依赖网络自身），但似乎也有必要<strong>标准化它们的评估流程</strong>。一种可能的解决方案是使用一个<strong>基准</strong>来为同样条件下训练的网络生成可视化结果。这样的标准化方法反过来也能实现基于指标的评估，而不是当前的解释性的分析。</li>
<li>另一个发展方向是<font color="#dddd00"><strong>同时可视化多个单元</strong></font>以更好地理解处于研究中的<strong>表征的分布式</strong>方面，甚至同时还能遵循一种<strong>受控式方法</strong>。</li>
</ul>
</blockquote>
<p>&emsp;&emsp;以下是基于 <strong>ablation study 的方法</strong>的潜在研究方向：</p>
<blockquote>
<ul>
<li><font color="#dddd00"><strong>使用共同的系统性组织的数据集</strong></font>，其中带有计算机视觉领域常见的不同难题（比如视角和光照变化），并且还必需有复杂度更大的类别（比如纹理、部件和目标上的复杂度）。事实上，近期已经出现了这样的数据集 [6]。在这样的数据集上使用 ablation study，加上对所得到的混淆矩阵的分析，可以确定 CNN 架构出错的模式，进而实现更好的理解。</li>
<li>此外，对<font color="#dddd00"><strong>多个协同的 ablation 对模型表现的影响方式的系统性</strong></font>研究是很受关注的。这样的研究应该能延伸我们对独立单元的工作方式的理解。</li>
</ul>
</blockquote>
<p>&emsp;&emsp;最后，这些<strong>受控方法</strong>是很有前景的未来研究方向；因为相比于完全基于学习的方法，这些方法能让我们对这些<strong>系统的运算和表征</strong>有更深入的理解。这些有趣的<strong>研究方向</strong>包括：</p>
<blockquote>
<ul>
<li><font color="#dddd00"><strong>逐步固定网络参数和分析对网络行为的影响</strong></font>。比如，<strong>一次固定一层的卷积核参数</strong>（基于当前已有的对该任务的先验知识），以<strong>分析所采用的核在每一层的适用性</strong>。这个渐进式的方法有望揭示学习的作用，而且也可用作<strong>最小化训练时间的初始化方法</strong>。</li>
<li>类似地，可以<font color="#dddd00"><strong>通过分析输入信号的性质（比如信号中的常见内容）来研究网络架构本身的设计</strong></font>（比如层的数量或每层中过滤器的数量）。这种方法有助于让架构达到<strong>适宜应用的复杂度</strong>。</li>
<li>最后，将<font color="#dddd00"><strong>受控方法用在网络实现上的同时可以对 CNN 的其它方面的作用进行系统性的研究</strong></font>，由于人们重点关注的所学习的参数，所以这方面得到的关注较少。比如，可以在大多数所学习的参数固定时，研究各种<strong>池化策略和残差连接</strong>的作用。</li>
</ul>
</blockquote>
<p>&lt;/br&gt;</p>
<blockquote>
<p>作者原文链接：<a href="https://blog.csdn.net/weixin_42691585/article/details/107699715" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42691585/article/details/107699715</a></p>
</blockquote>
</div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习    </a><a class="post-meta__tags" href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">卷积神经网络    </a><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理    </a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习    </a><a class="post-meta__tags" href="/tags/%E7%AE%97%E6%B3%95/">算法    </a></div><div class="post_share"></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/08/01/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%88%9D%E5%A7%8B%E5%8C%96Vue%E9%A1%B9%E7%9B%AE%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%9C%A8github%E4%B8%8A/"><img class="prev_cover lazyload" data-src="https://img-blog.csdnimg.cn/20200730171405910.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1YW45NTAyMDU=,size_16,color_FFFFFF,t_70" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>手把手教你初始化Vue项目并部署在github上</span></div></a></div><div class="next-post pull_right"><a href="/2020/07/30/%E8%AF%BB%E5%86%99excel/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.2/img/闫凯峰/7.30/python大法好.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>读写excel</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/11/【自我学习】胶囊网络CapsNet/" title="【自我学习】胶囊网络CapsNet"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200402110030173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1YW45NTAyMDU=,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-11</div><div class="relatedPosts_title">【自我学习】胶囊网络CapsNet</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/15/损失函数/" title="损失函数"><img class="relatedPosts_cover lazyload"data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/损失函数.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-15</div><div class="relatedPosts_title">损失函数</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/08/机器学习（1）/" title="机器学习（1）"><img class="relatedPosts_cover lazyload"data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/1.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-08</div><div class="relatedPosts_title">机器学习（1）</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/22/机器学习（2）/" title="机器学习（2）"><img class="relatedPosts_cover lazyload"data-src="https://gitee.com/zzyaiml/blogimg/raw/master/https://gitee.com/zzyaiml/blogimg/训练误差与测试误差.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-22</div><div class="relatedPosts_title">机器学习（2）</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/论文阅读：Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks/" title="论文阅读：Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/NLPlab406/NLPlab406.github.io@v1.5/img/朱鑫海/8.2/1.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">论文阅读：Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/02/传统的机器学习方法——决策树（上）/" title="传统的机器学习方法——决策树（上）"><img class="relatedPosts_cover lazyload"data-src="https://img-blog.csdnimg.cn/20200802172055879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-02</div><div class="relatedPosts_title">传统的机器学习方法——决策树（上）</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By 东北石油大学智能技术与自然语言处理实验室</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">欢迎来到我们团队的博客！</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>